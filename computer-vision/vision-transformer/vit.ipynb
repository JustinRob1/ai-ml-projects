{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTTiLM4iOQim",
        "outputId": "23e7f709-0a00-4df2-c1bc-06b64fb3b698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# NOTE: Make sure the external packages are installed in Colab\n",
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu\n",
        "!pip install matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W23oznYEOQin"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, RandomHorizontalFlip, RandomCrop, CenterCrop\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_metric_learning import miners, losses, distances\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKEKQo_9OQin",
        "outputId": "d859d620-2397-4a2d-ed48-51c253ae52b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Colab Patch\n",
        "use_colab = True\n",
        "if use_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import sys\n",
        "    # ----------------------------------------\n",
        "    dir = \"/content/drive/MyDrive/Colab Notebooks\"    \n",
        "    # ----------------------------------------\n",
        "    sys.path.append(dir)\n",
        "\n",
        "from vit_model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lvIpEPPOQin"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "# NOTE: Feel free to add & modify hyperparameters if needed\n",
        "num_epochs = 50\n",
        "batch_size = 512\n",
        "weight_decay = 1e-4\n",
        "lr = 0.001       \n",
        "\n",
        "# ViT specifics\n",
        "image_size = 28\n",
        "in_channels = 1\n",
        "patch_size = 4\n",
        "hidden_size = 64\n",
        "layers = 6\n",
        "heads = 8\n",
        "embed_size = 64\n",
        "\n",
        "# Contrastive Learning specifics\n",
        "margin = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaKArro5OQio"
      },
      "outputs": [],
      "source": [
        "# Load FashionMNIST dataset\n",
        "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "num_classes = len(classes)\n",
        "\n",
        "tfm_train = Compose([\n",
        "\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomCrop(size=(image_size, image_size)),\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, ), (0.5, )),\n",
        "    ])\n",
        "\n",
        "tfm_test = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, ), (0.5, )),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "pGTpwYQnOQio",
        "outputId": "bc042099-c2a3-489e-a2a2-6f103a5d4fd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def inverse_transform(\n",
        "    img_tensor: torch.Tensor,\n",
        "    ) -> np.ndarray:\n",
        "    \"\"\"Given a preprocessed image tensor, revert the normalization process and\n",
        "    convert the tensor back to a numpy image.\n",
        "    \"\"\"\n",
        "    inv_normalize = Normalize(mean=(-0.5/0.5, ), std=(1/0.5, ))\n",
        "    img_tensor = inv_normalize(img_tensor).permute(1, 2, 0)\n",
        "    img = np.uint8(255 * img_tensor.numpy())\n",
        "    return img\n",
        "\n",
        "# Get some random training images\n",
        "n_imgs = 5\n",
        "dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=tfm_train)\n",
        "indices = np.random.randint(0, len(dataset), size=(n_imgs, ))\n",
        "\n",
        "# Visualize with matplotlib\n",
        "for i, idx in enumerate(indices):\n",
        "    img_tensor, label = dataset[idx]\n",
        "    img = inverse_transform(img_tensor)\n",
        "    plt.subplot(1, n_imgs, i + 1)\n",
        "    plt.imshow(img, cmap=\"gray\")\n",
        "    plt.title(classes[label])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf0pO4z0OQio"
      },
      "outputs": [],
      "source": [
        "# Train a Classifier\n",
        "# -----\n",
        "\n",
        "def train_classification_model():\n",
        "    # Base ViT\n",
        "    vit_model = ViT(\n",
        "        image_size=image_size,\n",
        "        patch_size=patch_size,\n",
        "        num_channels=in_channels,\n",
        "        hidden_size=hidden_size,\n",
        "        layers=layers,\n",
        "        heads=heads)\n",
        "\n",
        "    # Classifier\n",
        "    model_classifier = ClassificationHead(hidden_size=vit_model.hidden_size, num_classes=num_classes)\n",
        "    if torch.cuda.is_available():\n",
        "        vit_model = vit_model.cuda()\n",
        "        model_classifier = model_classifier.cuda()\n",
        "\n",
        "    # Use cross entropy\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Specify optimizer\n",
        "    parameters = list(vit_model.parameters()) + list(model_classifier.parameters())\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        parameters,\n",
        "        lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Evaluate at the end of each epoch\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x, labels) in enumerate(train_loader):\n",
        "            vit_model.train()\n",
        "            model_classifier.train()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            feats = vit_model(x)\n",
        "            outputs = model_classifier(feats)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # NOTE: Show train loss at the end of epoch\n",
        "            if (i+1) % len(train_loader) == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "        # Evaluate at the end\n",
        "        test_acc = test_classification_model(vit_model, model_classifier)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            state_dict = {\n",
        "                \"classifier\": model_classifier.state_dict(),\n",
        "                \"vit\": vit_model.state_dict(),\n",
        "                \"acc\": best_acc,\n",
        "            }\n",
        "            torch.save(state_dict, \"vit_classifier.pt\")\n",
        "            print(\"Best test acc:\", best_acc)\n",
        "        print()\n",
        "\n",
        "def test_classification_model(\n",
        "    vit_model: nn.Module,\n",
        "    model_classifier: nn.Module,\n",
        "    ):\n",
        "    # Test the model\n",
        "    vit_model.eval()\n",
        "    model_classifier.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            feats = vit_model(images)\n",
        "            outputs = model_classifier(feats)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        # print('Test Accuracy: {} %'.format(100 * correct / total))\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O6039s4OQio"
      },
      "outputs": [],
      "source": [
        "# NOTE: Uncomment this to test your ViT implementation\n",
        "\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=tfm_train)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=tfm_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# train_classification_model()\n",
        "\n",
        "# del train_dataset\n",
        "# del test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2eTBXlOOQip",
        "outputId": "8b8f676a-f79c-482c-cd50-7fd6052d8b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num. samples in subset: 5000\n"
          ]
        }
      ],
      "source": [
        "# Sample a subset of training dataset\n",
        "# NOTE: sample an even number of samples per class\n",
        "# To migrate the problem of [class imbalancing]\n",
        "# (https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data).\n",
        "def sample_balanced_subset(\n",
        "    train_dataset,\n",
        "    n_samples_per_class: int = 50,\n",
        "    n_classes: int = 10\n",
        "    ):\n",
        "    maps = {i: [] for i in range(n_classes)}\n",
        "    for idx, (_, cls_idx) in enumerate(train_dataset):\n",
        "        if len(maps[cls_idx]) < n_samples_per_class:\n",
        "            maps[cls_idx].append(idx)\n",
        "\n",
        "    indices = []\n",
        "    for _, ind in maps.items():\n",
        "        indices += ind\n",
        "\n",
        "    train_subset = torch.utils.data.Subset(train_dataset, indices)\n",
        "    print(\"Num. samples in subset:\", len(train_subset))\n",
        "    return train_subset\n",
        "\n",
        "# Subsample a small subset from the full train dataset\n",
        "full_train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=tfm_train)\n",
        "train_dataset = sample_balanced_subset(full_train_dataset, n_samples_per_class=500)      # DO NOT MODIFY THIS CODE\n",
        "\n",
        "# Full test set will still be used for testing\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=tfm_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mOR98W7OQip"
      },
      "outputs": [],
      "source": [
        "# Train an embedding model\n",
        "# -----\n",
        "\n",
        "def train_embedding_model(\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    ):\n",
        "    #########################\n",
        "    # Finish Your Code HERE\n",
        "    # #########################\n",
        "\n",
        "    # Dataloader\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Evaluate model per epoch, and keep track of the model performance at that time\n",
        "    best_prec = 0.0\n",
        "\n",
        "    # Triplet Loss with Semi-hard triples & l2 distance\n",
        "    # -------------------\n",
        "    # Source: https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR\n",
        "    #         https://kevinmusgrave.github.io/pytorch-metric-learning/distances/\n",
        "\n",
        "\n",
        "    distance = distances.LpDistance(power=2)\n",
        "    criterion = losses.TripletMarginLoss(margin=0.2, distance=distance)\n",
        "    miner = miners.TripletMarginMiner(margin=0.2, distance=distance, type_of_triplets=\"semihard\")        # Make sure to use \"semihard\" triplets\n",
        "    # -------------------\n",
        "\n",
        "    # Precision to test embedding quality\n",
        "    accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)\n",
        "\n",
        "    # Models to train\n",
        "    # -------------------\n",
        "    vit_model = ViT(image_size, patch_size, in_channels, hidden_size, layers, heads)\n",
        "    model_embedding = LinearEmbeddingHead(hidden_size, embed_size)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        vit_model = vit_model.cuda()\n",
        "        model_embedding = model_embedding.cuda()\n",
        "\n",
        "    # -------------------\n",
        "\n",
        "    # Specify optimizer\n",
        "    # -------------------\n",
        "    parameters = list(vit_model.parameters()) + list(model_embedding.parameters())      \n",
        "\n",
        "    optimizer = torch.optim.AdamW(parameters, lr=lr, weight_decay=weight_decay) \n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0) \n",
        "\n",
        "    # -------------------\n",
        "\n",
        "    # Train loop\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x, labels) in enumerate(train_loader):\n",
        "            vit_model.train()\n",
        "            model_embedding.train()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            # -------------------\n",
        "            embeddings = model_embedding(vit_model(x))\n",
        "            loss = criterion(embeddings, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # -------------------\n",
        "\n",
        "            # NOTE: Show train loss at the end of epoch\n",
        "            # Feel free to modify this to log more steps\n",
        "            if (i+1) % len(train_loader) == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "        # Evaluate at the end\n",
        "        best_prec = evaluate_at_end_epoch(vit_model, model_embedding, accuracy_calculator, best_prec, train_dataset, test_dataset)\n",
        "\n",
        "    # #########################\n",
        "\n",
        "def get_embeddings(\n",
        "    x: torch.Tensor,\n",
        "    vit_model: nn.Module,\n",
        "    model_embedding: nn.Module,\n",
        "    ) -> torch.Tensor:\n",
        "    \"\"\"Calculate embeddings for a batch of images.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vit_model.eval()\n",
        "        model_embedding.eval()\n",
        "        x_embeds = model_embedding(vit_model(x))\n",
        "\n",
        "    x_embeds = x_embeds.cpu()   # Cast to CPU\n",
        "    x_embeds = torch.nn.functional.normalize(x_embeds, p=2, dim=1)      # Extra Step: Normalize the embeddings\n",
        "    return x_embeds\n",
        "\n",
        "def get_embeddings_over_dataset(\n",
        "    dataset,\n",
        "    vit_model: nn.Module,\n",
        "    model_embedding: nn.Module,\n",
        "    ):\n",
        "    \"\"\"Loop through a full dataset and return all embeddings.\n",
        "    \"\"\"\n",
        "    # Create a loader on the go\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    X_embeds, Y = [], []\n",
        "    for i, (x, y) in enumerate(tqdm.tqdm(loader)):\n",
        "        x_embeds = get_embeddings(x, vit_model, model_embedding)\n",
        "        X_embeds.append(x_embeds)\n",
        "        Y.append(y)\n",
        "\n",
        "    X_embeds = torch.cat(X_embeds, dim=0)\n",
        "    Y = torch.cat(Y, dim=0)\n",
        "    return X_embeds, Y\n",
        "\n",
        "def test_embedding_model(\n",
        "    vit_model: nn.Module,\n",
        "    model_embedding: nn.Module,\n",
        "    accuracy_calculator,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    ):\n",
        "    # Test the model\n",
        "    model_embedding.eval()\n",
        "\n",
        "    X_embeds, Y = get_embeddings_over_dataset(train_dataset, vit_model, model_embedding)\n",
        "    X_embeds_test, Y_test = get_embeddings_over_dataset(test_dataset, vit_model, model_embedding)\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        X_embeds_test, Y_test, X_embeds, Y, False\n",
        "    )\n",
        "    return accuracies[\"precision_at_1\"]\n",
        "\n",
        "def evaluate_at_end_epoch(\n",
        "    vit_model: nn.Module,\n",
        "    model_embedding: nn.Module,\n",
        "    accuracy_calculator,\n",
        "    best_prec: float,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    ):\n",
        "    # Evaluate at the end\n",
        "    prec = test_embedding_model(vit_model, model_embedding, accuracy_calculator, train_dataset, test_dataset)\n",
        "    if prec > best_prec:\n",
        "        best_prec = prec\n",
        "        state_dict = {\n",
        "            \"embedding_head\": model_embedding.state_dict(),\n",
        "            \"vit\": vit_model.state_dict(),\n",
        "            \"precision@1\": prec,\n",
        "        }\n",
        "        torch.save(state_dict, \"vit_embeds.pt\")\n",
        "        print(\"Best Precision@1:\", best_prec)\n",
        "    print()\n",
        "    return best_prec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVKxJugpOQiq",
        "outputId": "8fe5f7df-24e1-4d5c-ac3d-4281d2d757fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [10/10], Loss: 0.1566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.75it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.6967\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  x.storage().data_ptr() + x.storage_offset() * 4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/50], Step [10/10], Loss: 0.1937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.79it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7115\n",
            "\n",
            "Epoch [3/50], Step [10/10], Loss: 0.1932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.82it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7244\n",
            "\n",
            "Epoch [4/50], Step [10/10], Loss: 0.1860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.62it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7341000000000001\n",
            "\n",
            "Epoch [5/50], Step [10/10], Loss: 0.2052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.66it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [6/50], Step [10/10], Loss: 0.2097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.05it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7354\n",
            "\n",
            "Epoch [7/50], Step [10/10], Loss: 0.1886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.74it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7381000000000001\n",
            "\n",
            "Epoch [8/50], Step [10/10], Loss: 0.2058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  6.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7542\n",
            "\n",
            "Epoch [9/50], Step [10/10], Loss: 0.1928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.78it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7627\n",
            "\n",
            "Epoch [10/50], Step [10/10], Loss: 0.2029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.768\n",
            "\n",
            "Epoch [11/50], Step [10/10], Loss: 0.1558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.78it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7727\n",
            "\n",
            "Epoch [12/50], Step [10/10], Loss: 0.2266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.54it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7773\n",
            "\n",
            "Epoch [13/50], Step [10/10], Loss: 0.1791\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.60it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7851\n",
            "\n",
            "Epoch [14/50], Step [10/10], Loss: 0.2422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.54it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [15/50], Step [10/10], Loss: 0.2078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.42it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [16/50], Step [10/10], Loss: 0.1998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.74it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7891\n",
            "\n",
            "Epoch [17/50], Step [10/10], Loss: 0.1965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.45it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [18/50], Step [10/10], Loss: 0.1790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.65it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7899\n",
            "\n",
            "Epoch [19/50], Step [10/10], Loss: 0.1926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.17it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7932\n",
            "\n",
            "Epoch [20/50], Step [10/10], Loss: 0.1920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.72it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7956000000000001\n",
            "\n",
            "Epoch [21/50], Step [10/10], Loss: 0.1894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.43it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.7979\n",
            "\n",
            "Epoch [22/50], Step [10/10], Loss: 0.2233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.84it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8038000000000001\n",
            "\n",
            "Epoch [23/50], Step [10/10], Loss: 0.2276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.05it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [24/50], Step [10/10], Loss: 0.1877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.51it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8052\n",
            "\n",
            "Epoch [25/50], Step [10/10], Loss: 0.2308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.55it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [26/50], Step [10/10], Loss: 0.2215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.79it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [27/50], Step [10/10], Loss: 0.2208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.55it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [28/50], Step [10/10], Loss: 0.2057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.63it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8069000000000001\n",
            "\n",
            "Epoch [29/50], Step [10/10], Loss: 0.2003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.74it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8095\n",
            "\n",
            "Epoch [30/50], Step [10/10], Loss: 0.2068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.74it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [31/50], Step [10/10], Loss: 0.1839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.54it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8134\n",
            "\n",
            "Epoch [32/50], Step [10/10], Loss: 0.2225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.45it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [33/50], Step [10/10], Loss: 0.2050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.37it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8192\n",
            "\n",
            "Epoch [34/50], Step [10/10], Loss: 0.2062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.23it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [35/50], Step [10/10], Loss: 0.1981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.74it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [36/50], Step [10/10], Loss: 0.1964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.13it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [37/50], Step [10/10], Loss: 0.2107\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.29it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [38/50], Step [10/10], Loss: 0.2339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.24it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8222\n",
            "\n",
            "Epoch [39/50], Step [10/10], Loss: 0.2278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.63it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [40/50], Step [10/10], Loss: 0.1952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.50it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [41/50], Step [10/10], Loss: 0.1999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.48it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [42/50], Step [10/10], Loss: 0.2018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.50it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [43/50], Step [10/10], Loss: 0.2055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.53it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  9.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [44/50], Step [10/10], Loss: 0.2381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.57it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  5.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [45/50], Step [10/10], Loss: 0.2092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.58it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8243\n",
            "\n",
            "Epoch [46/50], Step [10/10], Loss: 0.2140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.20it/s]\n",
            "100%|██████████| 20/20 [00:03<00:00,  6.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8270000000000001\n",
            "\n",
            "Epoch [47/50], Step [10/10], Loss: 0.2325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.55it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [48/50], Step [10/10], Loss: 0.2209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.61it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  7.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [49/50], Step [10/10], Loss: 0.2215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Precision@1: 0.8298000000000001\n",
            "\n",
            "Epoch [50/50], Step [10/10], Loss: 0.2097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  6.70it/s]\n",
            "100%|██████████| 20/20 [00:02<00:00,  8.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()    # Clean-up memory 1st\n",
        "train_embedding_model(train_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40QY6snAOQiq",
        "outputId": "4170a090-366d-4756-da55-ff7b3e5eea71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()    # Clean-up memory 1st\n",
        "\n",
        "# Load your trained model\n",
        "# Base ViT\n",
        "vit_model = ViT(\n",
        "    image_size=image_size,\n",
        "    patch_size=patch_size,\n",
        "    num_channels=in_channels,\n",
        "    hidden_size=hidden_size,\n",
        "    layers=layers,\n",
        "    heads=heads)\n",
        "\n",
        "# Embedding head\n",
        "model_embedding = LinearEmbeddingHead(hidden_size=vit_model.hidden_size, embed_size=embed_size)\n",
        "if torch.cuda.is_available():\n",
        "    vit_model = vit_model.cuda()\n",
        "    model_embedding = model_embedding.cuda()\n",
        "\n",
        "# Load saved checkpoint\n",
        "checkpoint = torch.load(\"vit_embeds.pt\")\n",
        "vit_model.load_state_dict(checkpoint[\"vit\"])\n",
        "model_embedding.load_state_dict(checkpoint[\"embedding_head\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgcF0x9xOQiq",
        "outputId": "db4487b9-39f8-46d1-8330-a7f130d0c427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num. samples in subset: 250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.46it/s]\n"
          ]
        }
      ],
      "source": [
        "# Sample a bank, which is a small subset of trainset\n",
        "bank = sample_balanced_subset(train_dataset, n_samples_per_class=25)\n",
        "X_bank_embeds, Y_bank = get_embeddings_over_dataset(bank, vit_model=vit_model, model_embedding=model_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "BxVSHFwJOQiq",
        "outputId": "cd99348b-6e3f-4aed-e065-db9471ffa38d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x300 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Deep KNN\n",
        "def retrieve_topk_nearest_neighbors_l2(\n",
        "    query: torch.Tensor,\n",
        "    ref: torch.Tensor,\n",
        "    k: int = 5,\n",
        "    ):\n",
        "    \"\"\"Calculate L2 distance between query and ref embeddings.\n",
        "    Return the top-k scores and the indices of the top-k scores.\n",
        "    \"\"\"\n",
        "    # Sources: https://pytorch.org/docs/stable/generated/torch.norm.html\n",
        "    #          https://pytorch.org/docs/stable/generated/torch.topk.html\n",
        "\n",
        "    l2_distances = torch.norm(query - ref, dim=1, p=2)\n",
        "    top_k_scores, indices = torch.topk(l2_distances, k, largest=False, sorted=True)\n",
        "    return top_k_scores, indices\n",
        "\n",
        "# Grab some samples in test set\n",
        "dataiter = iter(test_loader)\n",
        "X, Y = next(dataiter)\n",
        "X_embeds = get_embeddings(X, vit_model=vit_model, model_embedding=model_embedding)\n",
        "\n",
        "# One random sample\n",
        "idx = np.random.randint(0, X.shape[0])\n",
        "img, label, embed = X[idx], Y[idx], X_embeds[idx]\n",
        "\n",
        "# Get top-k nearest samples\n",
        "values, indices = retrieve_topk_nearest_neighbors_l2(embed.unsqueeze(0), X_bank_embeds)\n",
        "\n",
        "# Visualize results\n",
        "_, axes = plt.subplots(1, 6, figsize=(18, 3))\n",
        "axes[0].imshow(inverse_transform(img), cmap=\"gray\")\n",
        "axes[0].set_title(classes[label])\n",
        "for i, ind in enumerate(indices):\n",
        "    img_bank, label_bank = bank[ind]\n",
        "    axes[i + 1].imshow(inverse_transform(img_bank), cmap=\"gray\")\n",
        "    axes[i + 1].set_title(\"{}\\nScore: {:.3f}\".format(classes[label_bank], values[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuVb-ijzOQiq"
      },
      "outputs": [],
      "source": [
        "# Train a Classifier\n",
        "# -----\n",
        "\n",
        "def train_classification_model_head_only(\n",
        "    vit_model: nn.Module,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    num_epochs: int = 10,\n",
        "    ):\n",
        "    # Classifier\n",
        "    model_classifier = ClassificationHead(hidden_size=vit_model.hidden_size, num_classes=num_classes)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model_classifier = model_classifier.cuda()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model_classifier.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x, labels) in enumerate(train_loader):\n",
        "            vit_model.eval()\n",
        "            model_classifier.train()\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            feats = vit_model(x)\n",
        "            outputs = model_classifier(feats)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % len(train_loader) == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "        test_acc = test_classification_model(vit_model, model_classifier)\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "\n",
        "        acc = best_acc\n",
        "\n",
        "    # You should return the weights of your trained model, and the classification score (accuracy)\n",
        "    return {\"acc\": acc, \"vit\": vit_model.state_dict(), \"classifier\":model_classifier.state_dict()}\n",
        "\n",
        "def test_classification_model(\n",
        "    vit_model: nn.Module,\n",
        "    model_classifier: nn.Module,\n",
        "    ):\n",
        "    # Test the model\n",
        "    vit_model.eval()\n",
        "    model_classifier.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            feats = vit_model(images)\n",
        "            outputs = model_classifier(feats)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        # print('Test Accuracy: {} %'.format(100 * correct / total))\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPeRat9aOQiq",
        "outputId": "1d249f5e-8f58-4705-a716-2ce2a9593fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [118/118], Loss: 0.6273\n",
            "Epoch [2/10], Step [118/118], Loss: 0.5051\n",
            "Epoch [3/10], Step [118/118], Loss: 0.4939\n",
            "Epoch [4/10], Step [118/118], Loss: 0.4198\n",
            "Epoch [5/10], Step [118/118], Loss: 0.4750\n",
            "Epoch [6/10], Step [118/118], Loss: 0.5966\n",
            "Epoch [7/10], Step [118/118], Loss: 0.3099\n",
            "Epoch [8/10], Step [118/118], Loss: 0.3692\n",
            "Epoch [9/10], Step [118/118], Loss: 0.3169\n",
            "Epoch [10/10], Step [118/118], Loss: 0.3848\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'acc': 0.8457,\n",
              " 'vit': OrderedDict([('patch_embed.projection.weight',\n",
              "               tensor([[[[ 0.0799,  0.1153,  0.3049,  0.0435],\n",
              "                         [-0.0124,  0.2405,  0.3249, -0.0685],\n",
              "                         [ 0.1102,  0.0616,  0.0275, -0.1191],\n",
              "                         [ 0.1066, -0.1578,  0.1920,  0.1234]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.2036, -0.2127, -0.2515, -0.1361],\n",
              "                         [ 0.0815, -0.1112,  0.1862,  0.0565],\n",
              "                         [-0.1126,  0.1013, -0.0860,  0.0704],\n",
              "                         [ 0.0738, -0.1635, -0.0690,  0.2252]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.2950,  0.2054,  0.0152, -0.0263],\n",
              "                         [-0.2377,  0.2526,  0.2530,  0.0593],\n",
              "                         [ 0.1681,  0.2272,  0.2952,  0.2169],\n",
              "                         [ 0.0703, -0.1611, -0.1394, -0.2309]]],\n",
              "               \n",
              "               \n",
              "                       ...,\n",
              "               \n",
              "               \n",
              "                       [[[-0.2543,  0.1328, -0.0047, -0.1168],\n",
              "                         [-0.2489, -0.1896,  0.1067, -0.1152],\n",
              "                         [-0.1244, -0.0438, -0.1341,  0.2123],\n",
              "                         [ 0.1086,  0.0837,  0.1140, -0.0175]]],\n",
              "               \n",
              "               \n",
              "                       [[[-0.2037,  0.1118,  0.2105,  0.1275],\n",
              "                         [ 0.2353, -0.1790, -0.1749,  0.0299],\n",
              "                         [ 0.2341, -0.2358, -0.1894, -0.2675],\n",
              "                         [ 0.0613, -0.2264, -0.1082, -0.0143]]],\n",
              "               \n",
              "               \n",
              "                       [[[ 0.1662, -0.2825, -0.1845, -0.1059],\n",
              "                         [ 0.0456, -0.0118, -0.0029,  0.1631],\n",
              "                         [-0.2354, -0.0050, -0.0938, -0.0836],\n",
              "                         [ 0.1855,  0.1069, -0.1295, -0.0935]]]], device='cuda:0')),\n",
              "              ('patch_embed.projection.bias',\n",
              "               tensor([ 0.1164, -0.2883,  0.0506,  0.1579,  0.0407,  0.2321, -0.2237,  0.1292,\n",
              "                       -0.2137,  0.0934, -0.1188, -0.0625, -0.0154,  0.0629, -0.1471,  0.0556,\n",
              "                        0.0675, -0.2121, -0.1200,  0.0756, -0.1584,  0.2235,  0.0679, -0.2558,\n",
              "                        0.1769, -0.0326, -0.0237, -0.0595,  0.1051,  0.0247,  0.1652, -0.2800,\n",
              "                       -0.1084, -0.1008, -0.0555,  0.2179, -0.1578, -0.0298, -0.1236, -0.1090,\n",
              "                       -0.0706, -0.0087, -0.0852,  0.0175,  0.0902,  0.1004,  0.2113, -0.1658,\n",
              "                       -0.1236,  0.0527,  0.0359, -0.2334,  0.1124,  0.2332,  0.0131,  0.1029,\n",
              "                       -0.1403,  0.2384,  0.0187, -0.1818,  0.1999, -0.0417,  0.0175,  0.0147],\n",
              "                      device='cuda:0')),\n",
              "              ('pos_embed.cls_token',\n",
              "               tensor([[[ 1.1569,  0.3094, -0.2078,  0.0045, -1.6009,  1.7550, -0.0046,\n",
              "                         -1.1488,  1.0558,  2.0283, -0.3077, -0.3053,  1.2509, -1.0905,\n",
              "                         -0.5048,  0.7835,  0.8622, -1.0377,  0.0468,  0.6296, -0.1634,\n",
              "                          1.1522,  0.7221,  0.3496, -0.6240, -1.2667, -1.9005, -0.7034,\n",
              "                         -0.2070,  2.4912,  0.1593, -1.1147, -0.1990, -0.1868, -0.9335,\n",
              "                         -0.0219, -0.5012, -0.1992,  0.2484, -1.0803,  1.5466, -0.6320,\n",
              "                          0.4513, -1.2822, -0.0351, -0.1604, -0.6697,  0.1029, -1.1232,\n",
              "                         -0.8524, -0.8510,  0.0038, -0.4452,  0.0588, -0.5925, -0.5332,\n",
              "                         -1.2869, -2.0945, -1.6082, -0.5106,  0.0829, -0.4760,  0.1111,\n",
              "                          0.0940]]], device='cuda:0')),\n",
              "              ('pos_embed.position_embeddings',\n",
              "               tensor([[[ 0.1035, -0.5567, -0.3700,  ..., -0.1485,  1.3897,  0.9773],\n",
              "                        [ 0.9045,  0.3109,  0.3449,  ..., -0.1445,  0.3119, -0.9707],\n",
              "                        [ 1.5807, -0.1461, -0.2867,  ..., -1.8425,  0.7511,  0.7648],\n",
              "                        ...,\n",
              "                        [ 0.1497,  1.4420, -0.6598,  ...,  1.4623, -0.1375, -0.0063],\n",
              "                        [-0.1274,  0.4446, -0.5401,  ...,  0.9238,  0.3345,  1.6993],\n",
              "                        [ 0.2558,  0.1504, -0.6931,  ...,  1.1772, -0.4520,  0.0215]]],\n",
              "                      device='cuda:0')),\n",
              "              ('ln_pre.weight',\n",
              "               tensor([1.0010, 1.0088, 0.9919, 1.0245, 1.0064, 1.0039, 1.0135, 0.9913, 1.0324,\n",
              "                       1.0026, 1.0147, 1.0033, 1.0107, 1.0131, 1.0155, 1.0136, 0.9999, 1.0153,\n",
              "                       1.0044, 1.0300, 1.0206, 1.0092, 1.0167, 1.0114, 1.0263, 1.0299, 1.0270,\n",
              "                       1.0163, 1.0333, 0.9932, 1.0515, 1.0044, 1.0244, 1.0321, 1.0296, 1.0075,\n",
              "                       1.0176, 1.0170, 1.0172, 0.9867, 1.0059, 1.0122, 1.0129, 1.0010, 1.0262,\n",
              "                       1.0178, 1.0407, 1.0535, 1.0488, 1.0367, 1.0118, 1.0289, 1.0083, 1.0236,\n",
              "                       1.0320, 1.0171, 1.0316, 1.0233, 1.0289, 1.0306, 1.0209, 1.0170, 1.0340,\n",
              "                       1.0417], device='cuda:0')),\n",
              "              ('ln_pre.bias',\n",
              "               tensor([-1.0930e-02, -2.2410e-03,  4.5863e-03, -3.8636e-03, -4.8062e-03,\n",
              "                       -4.4392e-03, -2.3909e-04,  2.4544e-03,  6.5930e-03, -6.7013e-04,\n",
              "                       -3.0002e-03,  3.1444e-03, -1.1168e-02,  6.7434e-03,  5.2826e-03,\n",
              "                        6.7825e-03, -2.5394e-03,  3.1296e-03,  1.1348e-03, -1.5578e-03,\n",
              "                       -4.4923e-03,  6.0576e-03,  3.9344e-03,  5.4047e-03,  2.2411e-03,\n",
              "                        1.7829e-03,  6.9356e-03,  1.5802e-03, -6.6029e-03, -6.4941e-03,\n",
              "                       -3.1939e-03,  6.4325e-03, -1.1768e-03,  3.2891e-03,  1.7312e-03,\n",
              "                       -4.2465e-03, -2.3186e-03, -3.5032e-03, -4.8507e-03,  9.6518e-03,\n",
              "                       -4.0952e-03,  1.8669e-03, -1.5104e-03, -3.6251e-03, -5.4440e-03,\n",
              "                        3.2762e-03, -6.9627e-04, -3.3872e-03, -4.7641e-03,  1.2178e-02,\n",
              "                       -3.3057e-04,  4.0098e-03,  1.6507e-02, -1.4021e-03,  3.3669e-03,\n",
              "                       -2.3556e-03, -3.8961e-03, -3.2793e-03, -5.3048e-03, -1.1653e-03,\n",
              "                       -1.4460e-03, -1.2321e-03,  2.7143e-03, -6.6242e-05], device='cuda:0')),\n",
              "              ('transformer.resblocks.0.attn.in_proj_weight',\n",
              "               tensor([[ 0.1349, -0.1213,  0.1321,  ..., -0.0839, -0.1674,  0.1142],\n",
              "                       [ 0.0486,  0.1400, -0.0970,  ..., -0.1545, -0.0813, -0.0373],\n",
              "                       [-0.1503, -0.0221, -0.0487,  ...,  0.0213, -0.0218,  0.0535],\n",
              "                       ...,\n",
              "                       [ 0.1450,  0.0151, -0.0595,  ...,  0.0387, -0.1068, -0.0267],\n",
              "                       [-0.0317,  0.0901, -0.0779,  ...,  0.0704,  0.0191,  0.1354],\n",
              "                       [ 0.1300, -0.0902, -0.0210,  ..., -0.0603,  0.0303, -0.0330]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.attn.in_proj_bias',\n",
              "               tensor([-1.2482e-02,  6.6455e-03, -6.6363e-03,  2.7336e-02, -6.0438e-03,\n",
              "                       -1.1988e-02,  3.6556e-03, -1.8732e-02,  2.4381e-03,  1.0076e-02,\n",
              "                        4.1891e-02,  9.4473e-03, -2.3082e-02,  3.3230e-02, -2.1355e-02,\n",
              "                        3.2629e-02, -4.7594e-03, -2.3049e-03, -1.8397e-02, -3.1978e-02,\n",
              "                       -1.2965e-02, -3.7825e-02, -2.2567e-02, -1.7904e-02,  6.5742e-03,\n",
              "                       -2.8300e-02,  1.7040e-02, -7.7368e-03,  8.7907e-03, -1.4920e-02,\n",
              "                        2.6615e-02,  6.0006e-03, -2.1803e-02,  1.0884e-03, -2.4565e-02,\n",
              "                        3.0066e-02, -2.9029e-02,  3.3173e-03,  3.6205e-02,  5.7600e-03,\n",
              "                       -8.7448e-03,  1.2200e-02,  9.7779e-04, -1.3581e-02, -3.1005e-02,\n",
              "                        2.0268e-02, -2.4322e-02, -6.1248e-03,  5.5657e-03, -2.2637e-02,\n",
              "                        5.8210e-03,  7.7467e-03, -6.0228e-03,  8.9029e-03, -2.5846e-02,\n",
              "                       -5.9208e-03, -1.3083e-02,  1.3233e-02, -9.6716e-03, -6.8057e-03,\n",
              "                       -2.4252e-02,  2.0604e-02,  2.7078e-02, -1.4291e-02,  2.9133e-04,\n",
              "                        1.0857e-04, -2.3535e-05,  2.2138e-04,  1.2056e-04,  1.0038e-05,\n",
              "                        7.9113e-05,  2.9002e-04, -3.8834e-05,  1.3530e-06, -3.6054e-04,\n",
              "                       -4.0231e-05,  1.9602e-03, -1.2193e-03,  1.1148e-03, -5.5641e-04,\n",
              "                       -1.8953e-04, -8.2178e-05, -1.3284e-04,  6.1129e-05, -7.6169e-05,\n",
              "                       -4.6567e-04,  5.9568e-04, -7.3047e-05, -1.6189e-04, -6.0612e-04,\n",
              "                        2.1924e-04, -1.2300e-04,  2.7712e-04,  2.8567e-04, -1.9940e-03,\n",
              "                        1.8143e-04, -8.5123e-05,  7.6421e-05, -5.8331e-04, -1.7518e-04,\n",
              "                       -4.7269e-04,  1.5789e-04, -5.9345e-04, -3.0893e-04, -3.3673e-05,\n",
              "                        6.7616e-05, -8.5544e-05,  5.9331e-05,  1.5844e-04, -3.4043e-04,\n",
              "                        4.5992e-04,  1.3551e-04, -2.2113e-04, -1.1780e-04, -3.4880e-05,\n",
              "                        5.5273e-05, -1.2487e-04,  1.5944e-04,  3.4872e-05, -1.8542e-04,\n",
              "                        1.8401e-05, -1.2100e-05,  3.1528e-05,  2.6026e-04,  9.7713e-05,\n",
              "                        3.7470e-05, -5.7205e-06, -5.5056e-05,  3.4081e-03,  4.7451e-03,\n",
              "                       -8.6097e-04,  4.7008e-03, -1.5016e-03, -5.4007e-03,  5.7723e-03,\n",
              "                        6.8483e-03,  4.1881e-04, -1.0525e-03,  1.4261e-03,  3.4430e-03,\n",
              "                       -5.0377e-03,  1.0590e-03,  6.5193e-03,  1.1731e-03, -1.4837e-03,\n",
              "                        3.5469e-03, -6.1438e-03, -4.4187e-04, -2.9564e-03,  4.5204e-03,\n",
              "                        6.0485e-03, -3.6741e-03,  2.2212e-03, -1.8223e-04,  8.8239e-03,\n",
              "                       -1.9458e-03, -1.1525e-03, -1.2748e-03, -4.4611e-03,  3.9225e-03,\n",
              "                        1.9982e-03,  5.7291e-04, -2.2898e-03, -3.8325e-03,  2.0598e-03,\n",
              "                        3.0458e-03,  9.8178e-03, -8.0421e-04,  1.3732e-03,  5.0894e-04,\n",
              "                       -1.5507e-03,  3.5010e-03, -2.4867e-03,  1.1244e-02,  6.1298e-03,\n",
              "                        7.2306e-04,  3.9765e-04,  4.4146e-04, -1.7759e-04,  1.4458e-03,\n",
              "                        1.7909e-03, -6.0148e-03, -2.7672e-03,  3.8812e-03,  5.0945e-03,\n",
              "                        2.0369e-03, -1.2963e-03, -5.4925e-03,  3.7003e-03, -1.4577e-03,\n",
              "                        5.4008e-03, -1.8069e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.0.attn.out_proj.weight',\n",
              "               tensor([[-0.0710,  0.0781,  0.1112,  ...,  0.0333, -0.0475, -0.0434],\n",
              "                       [ 0.0459,  0.0644, -0.0033,  ...,  0.0515, -0.0616,  0.0196],\n",
              "                       [ 0.0274,  0.0712, -0.0762,  ..., -0.0696,  0.1119, -0.1131],\n",
              "                       ...,\n",
              "                       [-0.0691, -0.0337, -0.0669,  ..., -0.1193, -0.0087,  0.0077],\n",
              "                       [ 0.0400, -0.0967,  0.0984,  ..., -0.1264,  0.0095,  0.0843],\n",
              "                       [-0.0301, -0.0313,  0.0380,  ...,  0.0540,  0.0179, -0.0814]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.attn.out_proj.bias',\n",
              "               tensor([-9.9572e-03,  2.3757e-03,  1.9694e-03, -5.3575e-03, -6.2618e-03,\n",
              "                       -6.7415e-03, -1.6551e-04, -1.1313e-03,  4.7676e-04, -1.3520e-04,\n",
              "                       -1.9360e-03,  7.0060e-03, -2.4732e-03,  5.3391e-03,  5.1607e-03,\n",
              "                        2.7025e-03, -4.0841e-03, -1.7110e-03,  3.6130e-03, -9.8606e-04,\n",
              "                       -6.7801e-03,  4.7006e-03,  2.7481e-04,  1.8702e-03,  1.9225e-03,\n",
              "                        3.7925e-03,  5.4178e-03, -4.2290e-03, -1.2598e-03, -1.9688e-03,\n",
              "                       -6.9212e-03,  1.5725e-03,  9.5527e-05,  4.8165e-03,  1.1239e-03,\n",
              "                       -1.3369e-03,  3.1326e-04, -4.3980e-03, -4.6763e-03,  8.7558e-03,\n",
              "                       -7.3216e-03,  2.5553e-03, -2.6365e-03, -1.2879e-03, -2.9242e-03,\n",
              "                        2.8769e-03,  1.2657e-03, -2.9059e-03,  1.0668e-03,  1.0923e-02,\n",
              "                        4.9797e-03,  3.9902e-03,  1.1033e-02, -2.1654e-03, -9.1743e-04,\n",
              "                        1.1309e-03,  1.5390e-03, -1.2094e-03,  4.6096e-04, -3.0143e-03,\n",
              "                        1.4911e-03, -1.4562e-03, -1.1295e-03, -1.2990e-04], device='cuda:0')),\n",
              "              ('transformer.resblocks.0.ln_1.weight',\n",
              "               tensor([1.0158, 1.0342, 1.0168, 1.0508, 1.0179, 1.0548, 1.0323, 0.9971, 1.0347,\n",
              "                       1.0454, 1.0107, 1.0080, 0.9956, 1.0567, 0.9882, 1.0259, 1.0076, 1.0386,\n",
              "                       1.0437, 1.0128, 1.0435, 1.0017, 1.0397, 1.0144, 1.0418, 1.0289, 1.0456,\n",
              "                       1.0985, 1.0403, 0.9996, 1.0227, 1.0297, 1.0271, 1.0359, 1.0753, 0.9941,\n",
              "                       1.0190, 1.0730, 1.0476, 0.9917, 1.0443, 1.0325, 1.0533, 1.0361, 1.0661,\n",
              "                       1.0167, 1.0416, 1.0597, 0.9934, 1.0105, 1.0258, 1.0081, 1.0196, 1.0519,\n",
              "                       1.0405, 1.0557, 1.0449, 1.0348, 1.0408, 1.0358, 1.0321, 1.0172, 1.0563,\n",
              "                       1.0185], device='cuda:0')),\n",
              "              ('transformer.resblocks.0.ln_1.bias',\n",
              "               tensor([ 0.0085, -0.0194, -0.0020,  0.0118, -0.0126,  0.0307, -0.0186,  0.0292,\n",
              "                        0.0310,  0.0495,  0.0232, -0.0209, -0.0087,  0.0058, -0.0280,  0.0086,\n",
              "                        0.0148,  0.0364, -0.0150,  0.0167,  0.0010, -0.0195,  0.0448,  0.0198,\n",
              "                       -0.0240, -0.0193, -0.0212,  0.0442,  0.0091,  0.0066,  0.0344,  0.0229,\n",
              "                       -0.0093, -0.0127, -0.0021, -0.0198, -0.0207,  0.0201,  0.0009,  0.0101,\n",
              "                        0.0411, -0.0021,  0.0349, -0.0312, -0.0346,  0.0096, -0.0323,  0.0284,\n",
              "                       -0.0157, -0.0040, -0.0127,  0.0089, -0.0115,  0.0219,  0.0470, -0.0231,\n",
              "                       -0.0474, -0.0313, -0.0341, -0.0105, -0.0230, -0.0113,  0.0476,  0.0192],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.mlp.0.weight',\n",
              "               tensor([[ 0.0190, -0.0824,  0.0666,  ..., -0.1462, -0.0853,  0.1024],\n",
              "                       [-0.0632,  0.0896, -0.0496,  ..., -0.0318, -0.0633, -0.0677],\n",
              "                       [-0.0745,  0.0010, -0.0598,  ..., -0.1134, -0.1220, -0.0787],\n",
              "                       ...,\n",
              "                       [-0.0335, -0.0985, -0.0297,  ..., -0.0363,  0.0114,  0.0564],\n",
              "                       [-0.0116, -0.0254,  0.0104,  ..., -0.1083, -0.0124, -0.1133],\n",
              "                       [-0.0976, -0.0464,  0.1086,  ...,  0.0134, -0.0293,  0.0807]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.mlp.0.bias',\n",
              "               tensor([-0.0080, -0.0825, -0.0606, -0.0989,  0.0549, -0.0400,  0.0108,  0.0716,\n",
              "                       -0.0020,  0.0106, -0.0313, -0.0943,  0.0826, -0.0057,  0.1191,  0.0675,\n",
              "                        0.0229, -0.0626, -0.0327, -0.0829,  0.0965, -0.0915, -0.0599, -0.0376,\n",
              "                       -0.1208,  0.1118, -0.0808,  0.0445,  0.0402,  0.0138,  0.0763, -0.0272,\n",
              "                        0.0810, -0.0420, -0.1201,  0.0468, -0.0469, -0.0645, -0.0858,  0.1126,\n",
              "                       -0.0928, -0.1208,  0.0859, -0.0512, -0.0110, -0.0711,  0.0312, -0.1060,\n",
              "                        0.1173,  0.0167,  0.0147, -0.1071, -0.1106, -0.0834,  0.0239, -0.0548,\n",
              "                        0.0363,  0.0121, -0.0516, -0.0486,  0.0056,  0.0325, -0.1158,  0.0178,\n",
              "                        0.0744, -0.0816, -0.0541, -0.1062, -0.0603, -0.0160,  0.0587, -0.1117,\n",
              "                       -0.0733,  0.0861, -0.0159, -0.0487,  0.0377,  0.1166,  0.0789,  0.1163,\n",
              "                        0.0173,  0.0239,  0.0924, -0.0549, -0.0991, -0.0225, -0.1288, -0.0335,\n",
              "                        0.1093,  0.0653, -0.1005, -0.1024, -0.0706,  0.0498,  0.0726, -0.0528,\n",
              "                        0.0951, -0.0074, -0.0702,  0.0150,  0.0104,  0.0985, -0.0008, -0.0329,\n",
              "                        0.1034, -0.0337,  0.0581,  0.1014, -0.0215,  0.1025, -0.0777, -0.0278,\n",
              "                        0.0463,  0.0721,  0.0048,  0.0202, -0.0089,  0.0366,  0.1063, -0.0946,\n",
              "                       -0.0473, -0.0366, -0.1010, -0.0606, -0.0776,  0.0486, -0.0136, -0.0011,\n",
              "                        0.0767, -0.0088, -0.1224,  0.0097, -0.0330, -0.0922,  0.0644,  0.0332,\n",
              "                       -0.0975,  0.0288, -0.1091, -0.0622, -0.0917,  0.0545, -0.0031,  0.1088,\n",
              "                       -0.0527,  0.0737,  0.0225, -0.0691,  0.0608, -0.0341, -0.0200, -0.0092,\n",
              "                       -0.0611,  0.0758, -0.1028, -0.1038, -0.0759, -0.0797,  0.0543,  0.0329,\n",
              "                       -0.1205,  0.0427, -0.0843,  0.0303,  0.0619, -0.0037,  0.0316,  0.1089,\n",
              "                        0.0287, -0.0516,  0.0482, -0.1311,  0.0307,  0.0019, -0.0131,  0.0644,\n",
              "                       -0.0056, -0.1139,  0.0592,  0.0511,  0.1215,  0.0119, -0.0002,  0.1040,\n",
              "                       -0.0470,  0.0175, -0.0949, -0.1304, -0.0822, -0.0091, -0.1294, -0.0848,\n",
              "                        0.0794,  0.0563, -0.0462, -0.0077, -0.0380,  0.0088, -0.1280,  0.0733,\n",
              "                       -0.0045, -0.0271, -0.1052,  0.0635,  0.0157, -0.0152, -0.1159, -0.0629,\n",
              "                       -0.0645, -0.0176,  0.0465, -0.0497,  0.0931, -0.0624, -0.0538, -0.0623,\n",
              "                        0.0768, -0.0029,  0.0203, -0.0651, -0.0588, -0.0871,  0.0456, -0.0574,\n",
              "                       -0.1167, -0.1130, -0.1099, -0.0817,  0.0684, -0.0173, -0.0567, -0.0326,\n",
              "                        0.0868,  0.1149, -0.0200,  0.0242,  0.0491, -0.0014,  0.0543, -0.0967,\n",
              "                        0.0242, -0.0068,  0.0699, -0.1163,  0.0559, -0.0908, -0.0331,  0.1107,\n",
              "                        0.0947, -0.0170,  0.0268,  0.1025, -0.0827,  0.0826, -0.0852, -0.0318],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.mlp.2.weight',\n",
              "               tensor([[ 0.0607, -0.0265,  0.0424,  ...,  0.0232,  0.0215, -0.0583],\n",
              "                       [-0.0116,  0.0419,  0.0466,  ..., -0.0186, -0.0283,  0.0408],\n",
              "                       [-0.0272,  0.0531, -0.0422,  ...,  0.0638, -0.0126, -0.0319],\n",
              "                       ...,\n",
              "                       [ 0.0290, -0.0372,  0.0515,  ..., -0.0367,  0.0145, -0.0249],\n",
              "                       [-0.0152, -0.0041,  0.0190,  ..., -0.0220, -0.0294,  0.0125],\n",
              "                       [-0.0367, -0.0040,  0.0051,  ..., -0.0507,  0.0181,  0.0081]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.mlp.2.bias',\n",
              "               tensor([-0.0198,  0.0036,  0.0402, -0.0427,  0.0278,  0.0564, -0.0382,  0.0588,\n",
              "                       -0.0256,  0.0330,  0.0207, -0.0431, -0.0329,  0.0249,  0.0002, -0.0523,\n",
              "                        0.0004,  0.0524, -0.0482,  0.0092, -0.0045, -0.0043, -0.0457,  0.0157,\n",
              "                       -0.0507,  0.0373, -0.0562,  0.0467,  0.0054, -0.0097,  0.0386, -0.0274,\n",
              "                        0.0527,  0.0614, -0.0227, -0.0376, -0.0153,  0.0595, -0.0219,  0.0276,\n",
              "                        0.0131,  0.0290, -0.0179,  0.0465, -0.0136,  0.0219,  0.0216,  0.0476,\n",
              "                        0.0603, -0.0167,  0.0658,  0.0394, -0.0020, -0.0124,  0.0479, -0.0533,\n",
              "                       -0.0131, -0.0035, -0.0403,  0.0417, -0.0042, -0.0298, -0.0017, -0.0119],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.0.ln_2.weight',\n",
              "               tensor([0.9946, 1.0028, 1.0172, 1.0230, 1.0075, 0.9822, 1.0089, 0.9848, 1.0105,\n",
              "                       0.9774, 0.9942, 0.9913, 1.0171, 1.0121, 1.0128, 1.0048, 0.9969, 0.9806,\n",
              "                       0.9944, 1.0190, 1.0066, 1.0037, 1.0092, 1.0082, 1.0337, 1.0415, 0.9965,\n",
              "                       1.0067, 1.0199, 0.9621, 1.0387, 0.9978, 1.0111, 1.0198, 1.0206, 1.0066,\n",
              "                       0.9950, 1.0064, 1.0247, 0.9952, 0.9988, 0.9694, 1.0101, 0.9716, 1.0017,\n",
              "                       1.0250, 1.0126, 1.0249, 1.0460, 1.0088, 0.9906, 1.0081, 0.9935, 0.9799,\n",
              "                       1.0052, 1.0166, 0.9995, 0.9884, 1.0062, 1.0348, 1.0284, 1.0217, 0.9930,\n",
              "                       1.0182], device='cuda:0')),\n",
              "              ('transformer.resblocks.0.ln_2.bias',\n",
              "               tensor([-4.8048e-03,  5.6728e-03, -1.4421e-03, -5.0310e-03, -5.4048e-03,\n",
              "                       -1.2291e-02, -8.3879e-03,  2.8062e-03,  5.6338e-03, -1.4543e-02,\n",
              "                       -8.1590e-05,  2.1137e-02, -3.8231e-04,  1.7957e-03,  6.1395e-03,\n",
              "                       -1.0037e-03, -5.0248e-03, -1.1910e-02,  1.2748e-02, -3.4598e-03,\n",
              "                       -2.1621e-02,  4.5909e-03, -3.3362e-03,  1.2137e-03, -2.8434e-04,\n",
              "                        8.7200e-03,  5.5542e-03,  5.2554e-03,  8.3288e-04, -8.5629e-03,\n",
              "                       -3.1524e-03, -1.2490e-02, -7.0887e-03, -1.6118e-03,  1.0616e-03,\n",
              "                       -2.0962e-03,  5.5460e-03, -4.2860e-03,  1.5880e-03,  1.2222e-02,\n",
              "                        3.3920e-03,  6.4360e-03,  3.4473e-03, -1.7692e-03, -7.4636e-03,\n",
              "                        3.7994e-03, -9.6999e-04, -7.0348e-03, -2.5283e-03,  4.6046e-03,\n",
              "                        8.4794e-03, -3.0965e-03,  1.1475e-02,  6.0159e-03, -1.5138e-02,\n",
              "                       -1.9110e-04,  3.6347e-03,  5.8477e-03,  3.1787e-03, -5.8012e-03,\n",
              "                        9.7465e-03,  9.4268e-03, -8.0440e-03,  2.4391e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.1.attn.in_proj_weight',\n",
              "               tensor([[-0.0725,  0.0297,  0.1605,  ..., -0.0842,  0.0263, -0.1434],\n",
              "                       [ 0.0753,  0.0010,  0.0581,  ...,  0.0699,  0.0776,  0.1235],\n",
              "                       [-0.1012, -0.1454, -0.1235,  ...,  0.0468,  0.0954,  0.0189],\n",
              "                       ...,\n",
              "                       [-0.1158,  0.1131, -0.0529,  ...,  0.1304,  0.0321, -0.1109],\n",
              "                       [-0.0819, -0.0088,  0.0707,  ...,  0.0228,  0.1035,  0.0803],\n",
              "                       [-0.0873, -0.0652,  0.0931,  ..., -0.0982,  0.0588, -0.1175]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.attn.in_proj_bias',\n",
              "               tensor([-9.4766e-03, -2.2829e-02, -2.5817e-02,  3.5455e-03,  1.0155e-02,\n",
              "                        1.7372e-02,  1.8843e-02,  1.9357e-03,  1.4452e-02,  4.2955e-03,\n",
              "                        7.4792e-03,  8.9169e-03,  1.9444e-03,  4.8722e-03,  1.2465e-02,\n",
              "                        1.9393e-02, -1.5154e-02,  1.5530e-02,  2.5001e-02, -2.1991e-02,\n",
              "                       -1.2773e-02, -1.5526e-02,  7.5737e-03, -2.3278e-02, -5.0599e-02,\n",
              "                       -5.8362e-04,  1.5274e-02, -1.8071e-02, -1.1379e-03, -1.8344e-02,\n",
              "                       -1.6124e-02,  7.5260e-03, -1.7562e-02,  3.2580e-03,  7.9981e-03,\n",
              "                        2.5362e-02, -4.2473e-03, -3.4078e-02,  6.3971e-03,  1.7164e-02,\n",
              "                       -1.1258e-02, -7.2250e-03,  1.1677e-02,  1.7707e-02,  2.4533e-03,\n",
              "                       -3.2613e-03, -1.8498e-03, -1.3156e-02, -1.1204e-02,  3.9106e-03,\n",
              "                        1.2822e-02,  2.2542e-02,  1.1890e-02, -1.3545e-03, -1.1179e-02,\n",
              "                        9.2927e-03, -1.0288e-02, -2.4666e-03,  1.8245e-02, -2.9948e-02,\n",
              "                        1.2224e-02,  1.5425e-02,  2.1546e-02, -1.1397e-02, -8.1871e-05,\n",
              "                       -1.0369e-04, -8.1949e-05, -8.6284e-06, -2.3532e-05,  2.6051e-05,\n",
              "                       -2.4896e-05,  9.2220e-06,  3.4076e-06,  2.7332e-05,  1.2772e-04,\n",
              "                        1.6611e-04,  5.6477e-05,  8.9789e-06, -1.4068e-04,  3.0008e-05,\n",
              "                       -9.3439e-06,  3.7988e-06,  1.2209e-04, -8.2479e-05,  1.1968e-05,\n",
              "                       -1.4074e-04,  8.2093e-05, -1.7342e-04, -4.3137e-04,  8.7575e-05,\n",
              "                       -2.5766e-05,  5.6851e-05,  1.3569e-04, -3.1976e-04, -3.2556e-05,\n",
              "                        4.4114e-04, -2.6646e-05,  9.9356e-05,  5.8128e-06, -2.5588e-04,\n",
              "                        2.7887e-05, -1.5405e-04, -1.0928e-04,  1.3131e-04,  9.6502e-05,\n",
              "                        7.9914e-05,  3.0427e-06, -4.3629e-05,  1.6255e-05,  1.5669e-04,\n",
              "                       -1.1966e-05,  4.7221e-05,  1.9459e-04, -3.1668e-05,  9.5121e-05,\n",
              "                        2.2769e-04, -1.4449e-04, -8.9058e-05,  1.1641e-04, -1.2324e-04,\n",
              "                       -1.5547e-04,  1.2024e-04,  4.9824e-05, -1.0530e-04, -1.5734e-04,\n",
              "                        2.1708e-04,  4.6872e-04, -3.4990e-04, -1.4619e-03, -1.5762e-04,\n",
              "                       -3.1334e-03, -2.3250e-03, -2.8675e-03, -1.4381e-03, -6.9624e-05,\n",
              "                       -8.7664e-03, -7.3583e-04,  3.3838e-03,  7.5536e-03,  1.4862e-03,\n",
              "                        5.2067e-03, -6.0644e-03,  2.5031e-03, -4.7332e-03, -1.8967e-03,\n",
              "                       -1.7443e-03,  1.6845e-03, -5.7110e-03,  3.6288e-03, -5.2120e-03,\n",
              "                        6.7349e-03,  8.7515e-03,  1.6089e-03,  1.6164e-03,  4.2893e-03,\n",
              "                        5.3872e-03, -4.9081e-03,  1.8831e-03, -1.7550e-03,  1.4196e-03,\n",
              "                       -2.4135e-03,  7.1754e-04,  3.4884e-03,  4.8447e-03,  4.0427e-03,\n",
              "                       -9.3023e-03, -5.4505e-03, -2.5473e-03, -1.7912e-03,  1.1062e-02,\n",
              "                        2.1198e-03, -5.0025e-04,  2.1104e-03, -4.4561e-03, -3.0639e-03,\n",
              "                       -5.4767e-03, -2.0600e-03,  7.5274e-04, -2.9016e-03,  1.7488e-03,\n",
              "                       -1.9506e-03,  4.2567e-03, -4.0196e-03,  1.5470e-03,  1.3192e-03,\n",
              "                        1.2245e-03,  1.9686e-03,  1.8782e-03, -8.3022e-05,  6.3806e-03,\n",
              "                        8.7852e-04, -9.8471e-04], device='cuda:0')),\n",
              "              ('transformer.resblocks.1.attn.out_proj.weight',\n",
              "               tensor([[ 0.0254,  0.0181,  0.0016,  ...,  0.0137, -0.0738,  0.0776],\n",
              "                       [ 0.0719,  0.0588,  0.0508,  ...,  0.0758,  0.0758, -0.0792],\n",
              "                       [ 0.0680,  0.0062,  0.0165,  ...,  0.0129,  0.1101,  0.0584],\n",
              "                       ...,\n",
              "                       [-0.0249,  0.0340,  0.0824,  ...,  0.0957,  0.1057, -0.0829],\n",
              "                       [ 0.0591, -0.0286,  0.0774,  ..., -0.0639, -0.0447, -0.0126],\n",
              "                       [-0.1209,  0.1075, -0.0909,  ...,  0.0159,  0.0170, -0.0421]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.attn.out_proj.bias',\n",
              "               tensor([-7.8557e-03, -2.1119e-03,  5.2125e-03, -6.7020e-03, -3.6178e-03,\n",
              "                       -4.4557e-03, -1.3118e-03,  1.3441e-03, -2.4961e-03,  2.7986e-04,\n",
              "                        2.3918e-03,  7.0233e-03, -5.2528e-03,  4.7603e-03,  4.2145e-03,\n",
              "                        4.2815e-04, -1.8622e-03, -4.9671e-03, -1.8535e-04,  3.3298e-04,\n",
              "                       -2.7230e-03,  4.1402e-03, -4.3182e-04,  1.6277e-03,  5.3021e-03,\n",
              "                        3.2755e-03,  3.9109e-03, -3.7340e-03, -1.2377e-03, -3.6379e-03,\n",
              "                       -1.6083e-03,  3.1519e-03,  3.6011e-05,  6.4341e-03, -1.6364e-03,\n",
              "                       -1.3760e-03,  3.6263e-03, -4.5670e-03, -4.5687e-03,  5.4978e-03,\n",
              "                       -8.3154e-03,  3.3580e-03, -2.6878e-03,  6.4453e-04, -1.3266e-03,\n",
              "                        1.4156e-03,  1.6738e-03,  7.1830e-05, -2.0385e-03,  6.0802e-03,\n",
              "                        3.1750e-03,  4.5762e-03,  4.6500e-03, -3.9044e-03, -1.8556e-03,\n",
              "                        1.9838e-03,  3.6189e-03, -1.9275e-03, -3.0029e-03,  3.3600e-03,\n",
              "                        3.0128e-03, -2.1733e-03,  2.8002e-03, -1.9917e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.1.ln_1.weight',\n",
              "               tensor([0.9841, 1.0451, 1.0121, 0.9777, 1.0201, 0.9975, 1.0107, 1.0140, 1.0582,\n",
              "                       1.0286, 1.0025, 1.0202, 1.0277, 1.0022, 1.0620, 1.0194, 1.0024, 0.9868,\n",
              "                       1.0276, 1.0194, 1.0321, 1.0391, 1.0129, 1.0175, 1.0467, 1.0531, 1.0367,\n",
              "                       1.0468, 1.0160, 0.9921, 1.0060, 1.0202, 1.0220, 1.0408, 0.9989, 1.0112,\n",
              "                       1.0205, 1.0242, 1.0325, 1.0057, 1.0122, 1.0165, 1.0209, 1.0006, 0.9988,\n",
              "                       1.0248, 1.0347, 1.0649, 1.0432, 1.0180, 1.0357, 1.0083, 1.0085, 1.0183,\n",
              "                       1.0421, 1.0306, 1.0306, 1.0130, 1.0137, 1.0072, 1.0007, 1.0267, 1.0234,\n",
              "                       1.0345], device='cuda:0')),\n",
              "              ('transformer.resblocks.1.ln_1.bias',\n",
              "               tensor([-0.0002, -0.0029, -0.0186, -0.0004, -0.0266, -0.0475,  0.0113,  0.0199,\n",
              "                        0.0211, -0.0094,  0.0030,  0.0019,  0.0114,  0.0132, -0.0063,  0.0049,\n",
              "                        0.0063,  0.0112,  0.0083,  0.0180, -0.0060,  0.0019, -0.0219, -0.0089,\n",
              "                       -0.0226,  0.0068, -0.0253,  0.0093,  0.0118, -0.0223,  0.0027,  0.0043,\n",
              "                       -0.0139, -0.0391,  0.0295,  0.0081, -0.0003,  0.0168,  0.0037, -0.0197,\n",
              "                        0.0040,  0.0016,  0.0145, -0.0103, -0.0110,  0.0308, -0.0038,  0.0175,\n",
              "                       -0.0117, -0.0121, -0.0229, -0.0112, -0.0255,  0.0022,  0.0079,  0.0195,\n",
              "                       -0.0404,  0.0173, -0.0088, -0.0046,  0.0099, -0.0025, -0.0033,  0.0535],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.mlp.0.weight',\n",
              "               tensor([[ 0.1059,  0.0992,  0.0135,  ..., -0.0146, -0.0352, -0.0447],\n",
              "                       [ 0.1032,  0.1419, -0.0752,  ..., -0.0214,  0.0029, -0.1025],\n",
              "                       [-0.0889,  0.0888,  0.0047,  ..., -0.0273,  0.0093,  0.0542],\n",
              "                       ...,\n",
              "                       [ 0.0591, -0.0909,  0.0041,  ...,  0.0995,  0.0787, -0.0836],\n",
              "                       [-0.0603, -0.0978, -0.0866,  ..., -0.0030,  0.0702,  0.0774],\n",
              "                       [ 0.0814,  0.0797,  0.0278,  ...,  0.0524,  0.1159, -0.0298]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.mlp.0.bias',\n",
              "               tensor([ 0.0068, -0.0925, -0.0479, -0.1234, -0.0614, -0.0830, -0.0046, -0.0218,\n",
              "                        0.0877,  0.0872,  0.0362,  0.0404,  0.0291,  0.0281, -0.0068,  0.0004,\n",
              "                       -0.0480, -0.0448, -0.0484,  0.0936, -0.0710, -0.0823,  0.0711, -0.0127,\n",
              "                        0.0408, -0.1156, -0.0184,  0.0037,  0.1077,  0.1230,  0.0693,  0.0447,\n",
              "                       -0.0468, -0.0189, -0.0591,  0.0914, -0.0608,  0.0294,  0.0797, -0.0093,\n",
              "                       -0.1023,  0.0393, -0.0481,  0.1085, -0.0787, -0.0175, -0.0331,  0.0621,\n",
              "                       -0.0746,  0.0966,  0.0860,  0.0635, -0.0373,  0.0659,  0.1129,  0.0042,\n",
              "                        0.0599, -0.1101,  0.0884, -0.0462, -0.1047,  0.0637, -0.0168,  0.0935,\n",
              "                       -0.0873,  0.0066, -0.0359, -0.1036, -0.0824, -0.0061,  0.0058,  0.1205,\n",
              "                        0.0122, -0.0823, -0.0283,  0.1162,  0.0697, -0.1069,  0.0454, -0.0583,\n",
              "                       -0.0183,  0.0225,  0.0121, -0.1045, -0.0077,  0.0532, -0.0515,  0.0988,\n",
              "                       -0.0795, -0.1053, -0.0623,  0.0082, -0.0120, -0.1326, -0.1110, -0.0672,\n",
              "                       -0.0198, -0.0106,  0.0733,  0.0140, -0.1050, -0.1341, -0.1020, -0.0671,\n",
              "                       -0.0660, -0.0807, -0.0205,  0.0681,  0.0376, -0.0708, -0.0778,  0.0823,\n",
              "                        0.0258,  0.0487,  0.0062, -0.0967,  0.0440, -0.0645, -0.1311,  0.0426,\n",
              "                       -0.1055,  0.0956,  0.0006, -0.0158, -0.0681,  0.0324,  0.1122,  0.0388,\n",
              "                       -0.0569, -0.0347,  0.0882,  0.1078,  0.0993, -0.0138,  0.0963, -0.0073,\n",
              "                        0.0992,  0.0713, -0.0780, -0.1266, -0.0446,  0.0137,  0.0954, -0.0147,\n",
              "                        0.1188, -0.0668, -0.1173,  0.0071,  0.0432,  0.0892,  0.0774, -0.0363,\n",
              "                        0.0637, -0.0398,  0.1068,  0.0202,  0.0303, -0.0717,  0.0175, -0.1284,\n",
              "                        0.0109, -0.0300,  0.0876, -0.0855, -0.1336, -0.0863, -0.0168,  0.0266,\n",
              "                        0.0067, -0.0685,  0.0255, -0.0450,  0.0944,  0.0038,  0.0328,  0.0332,\n",
              "                        0.0766,  0.0808,  0.0893, -0.0761, -0.0285,  0.0886,  0.0136, -0.0898,\n",
              "                       -0.0013,  0.0158,  0.0014, -0.1248,  0.0241,  0.0831, -0.0555, -0.0847,\n",
              "                       -0.1256, -0.0419,  0.0150,  0.0452,  0.0237,  0.0887, -0.0495, -0.0245,\n",
              "                        0.1063, -0.0655, -0.0304,  0.0439,  0.0753, -0.0345, -0.1062, -0.1154,\n",
              "                        0.0291,  0.0033,  0.0512, -0.0956,  0.0828,  0.0650, -0.0600, -0.0349,\n",
              "                       -0.0716,  0.0174, -0.0398, -0.0493, -0.0395, -0.0996,  0.0522,  0.0105,\n",
              "                        0.0018, -0.1083,  0.0815,  0.1057,  0.0190,  0.0689, -0.0507, -0.0126,\n",
              "                       -0.0543,  0.0644, -0.1004,  0.0765,  0.0548, -0.1146,  0.0343, -0.0341,\n",
              "                        0.0967, -0.0873, -0.0020,  0.1129,  0.0645, -0.1034,  0.1052,  0.0784,\n",
              "                        0.0404,  0.0212, -0.1197,  0.0027, -0.0203,  0.0192, -0.0129, -0.0402],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.mlp.2.weight',\n",
              "               tensor([[ 0.0116,  0.0256, -0.0409,  ..., -0.0189,  0.0180, -0.0447],\n",
              "                       [ 0.0302,  0.0665, -0.0386,  ..., -0.0594, -0.0414,  0.0320],\n",
              "                       [ 0.0824, -0.0234, -0.0030,  ...,  0.0206, -0.0122,  0.0496],\n",
              "                       ...,\n",
              "                       [ 0.0204,  0.0190,  0.0499,  ..., -0.0066,  0.0273,  0.0534],\n",
              "                       [-0.0160, -0.0537,  0.0234,  ...,  0.0040,  0.0385,  0.0563],\n",
              "                       [ 0.0290,  0.0553, -0.0321,  ..., -0.0053, -0.0581, -0.0696]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.mlp.2.bias',\n",
              "               tensor([-0.0575,  0.0126,  0.0070,  0.0548, -0.0354,  0.0040, -0.0074, -0.0537,\n",
              "                       -0.0539, -0.0171,  0.0524, -0.0111,  0.0535,  0.0520, -0.0467, -0.0571,\n",
              "                        0.0168, -0.0388, -0.0476,  0.0431,  0.0006,  0.0020, -0.0087,  0.0523,\n",
              "                        0.0252,  0.0488,  0.0198,  0.0461, -0.0132, -0.0639, -0.0289, -0.0277,\n",
              "                        0.0593, -0.0566,  0.0523,  0.0275,  0.0372,  0.0498, -0.0401,  0.0637,\n",
              "                       -0.0143,  0.0108, -0.0554, -0.0019,  0.0201, -0.0650, -0.0582,  0.0525,\n",
              "                       -0.0246,  0.0475,  0.0186, -0.0387,  0.0437, -0.0025, -0.0083,  0.0144,\n",
              "                       -0.0284, -0.0211,  0.0120, -0.0195, -0.0471, -0.0097,  0.0081,  0.0523],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.1.ln_2.weight',\n",
              "               tensor([0.9921, 1.0086, 0.9826, 1.0317, 0.9982, 1.0120, 1.0051, 0.9949, 0.9950,\n",
              "                       0.9813, 1.0025, 0.9916, 1.0102, 0.9933, 0.9983, 0.9904, 0.9675, 0.9912,\n",
              "                       0.9849, 1.0348, 1.0127, 0.9961, 0.9928, 1.0032, 0.9967, 0.9955, 0.9973,\n",
              "                       1.0312, 1.0220, 0.9784, 1.0091, 1.0049, 0.9956, 1.0245, 1.0059, 0.9762,\n",
              "                       1.0035, 0.9980, 1.0184, 0.9969, 1.0135, 0.9918, 0.9980, 0.9939, 1.0165,\n",
              "                       1.0136, 1.0170, 1.0291, 1.0238, 1.0330, 0.9973, 1.0200, 0.9945, 1.0092,\n",
              "                       1.0334, 0.9732, 0.9912, 1.0112, 1.0048, 1.0290, 1.0052, 1.0101, 0.9959,\n",
              "                       1.0066], device='cuda:0')),\n",
              "              ('transformer.resblocks.1.ln_2.bias',\n",
              "               tensor([-1.2763e-02, -1.2237e-03,  2.0081e-02, -3.4147e-03, -4.3960e-03,\n",
              "                       -5.6735e-03, -4.0411e-03,  3.3886e-03, -6.1907e-03, -1.1376e-02,\n",
              "                       -3.0502e-03,  5.2423e-03, -7.8888e-03,  3.7472e-03,  5.2800e-03,\n",
              "                       -7.2061e-03,  4.1631e-03, -8.2886e-03,  1.6451e-02,  2.4924e-03,\n",
              "                       -7.8466e-03, -6.6517e-04, -5.4680e-03, -2.2664e-03,  3.8059e-03,\n",
              "                        7.8424e-03,  5.3064e-03,  1.4396e-03, -1.6888e-02, -9.3997e-03,\n",
              "                        2.3110e-03,  5.0192e-04,  2.4366e-04,  4.6592e-03,  3.1871e-04,\n",
              "                        3.9287e-03,  5.3391e-03, -1.6628e-02, -7.2510e-03,  6.3638e-03,\n",
              "                       -6.4609e-03,  3.9621e-03, -4.9441e-03, -2.0870e-05,  9.1375e-05,\n",
              "                        3.0125e-03, -4.6932e-03,  7.8200e-04,  4.4829e-03, -2.1283e-03,\n",
              "                        4.6878e-04,  3.9175e-03,  1.3119e-02, -4.7427e-03, -8.0464e-03,\n",
              "                        1.9845e-02,  9.2773e-03, -1.0311e-03,  3.4001e-03, -1.6815e-03,\n",
              "                       -3.9394e-03, -1.9883e-02, -8.0120e-03, -4.7918e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.2.attn.in_proj_weight',\n",
              "               tensor([[-0.0212, -0.0814,  0.0769,  ...,  0.0657, -0.1064, -0.0541],\n",
              "                       [-0.0544, -0.1096,  0.1687,  ..., -0.1488, -0.0653,  0.1133],\n",
              "                       [ 0.0894,  0.0462, -0.1409,  ..., -0.1113, -0.1680, -0.0696],\n",
              "                       ...,\n",
              "                       [ 0.0762, -0.0114,  0.0436,  ...,  0.1221, -0.0141,  0.0967],\n",
              "                       [ 0.1244, -0.0347,  0.0478,  ...,  0.0411,  0.1098,  0.1094],\n",
              "                       [ 0.1241,  0.0303,  0.1416,  ...,  0.0638, -0.0631, -0.0376]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.attn.in_proj_bias',\n",
              "               tensor([-5.7607e-04,  5.7072e-03, -3.3445e-03, -3.0356e-02, -4.3003e-03,\n",
              "                       -3.1929e-03, -2.8347e-02, -5.4615e-04,  3.2965e-02, -4.4385e-02,\n",
              "                       -2.8424e-02,  1.9290e-02,  3.3155e-02,  2.8064e-02,  8.9973e-03,\n",
              "                        3.2668e-02, -1.6253e-02,  3.3540e-02, -1.6136e-02, -2.5720e-03,\n",
              "                        1.0282e-02, -2.0035e-02, -2.5507e-02, -1.1586e-03, -1.3620e-02,\n",
              "                        4.7834e-02,  2.5543e-02,  2.5606e-03, -1.3851e-03,  2.0500e-02,\n",
              "                       -1.0556e-03,  1.0631e-02,  6.1168e-03,  7.4232e-03, -2.0002e-03,\n",
              "                       -3.2003e-02,  5.6010e-03, -5.0585e-03,  3.5989e-03,  1.6932e-03,\n",
              "                       -4.1961e-03,  2.4782e-03,  1.0793e-03, -6.5736e-03, -2.4870e-02,\n",
              "                       -1.0496e-03, -4.4420e-03,  6.9757e-03, -2.6682e-03, -1.7539e-02,\n",
              "                       -1.6814e-02,  1.5560e-02,  6.4055e-03, -2.5239e-02,  1.5742e-02,\n",
              "                        3.6160e-03,  7.9183e-03, -2.0020e-03,  1.4293e-02,  1.4128e-02,\n",
              "                        1.8652e-02, -3.8800e-02,  9.3419e-03,  6.0503e-04, -6.8011e-05,\n",
              "                        1.7080e-04,  3.0073e-05, -1.8680e-04, -1.9282e-04,  5.3991e-05,\n",
              "                       -4.3354e-04,  1.0797e-04, -5.3896e-04, -1.7081e-03, -6.7497e-04,\n",
              "                        3.3063e-04,  1.2157e-03,  1.1101e-03, -2.7257e-04,  8.7204e-04,\n",
              "                        4.1926e-05,  6.5230e-06, -2.9218e-04,  4.2381e-05, -3.0893e-07,\n",
              "                       -4.1721e-05, -3.8511e-05, -3.7074e-04,  8.5416e-04, -9.1580e-04,\n",
              "                        1.2574e-04,  1.2149e-04, -1.0113e-06, -2.6333e-04, -2.0239e-04,\n",
              "                       -4.0292e-05, -9.5089e-06,  4.1495e-05, -4.8860e-05, -3.2388e-05,\n",
              "                        1.1020e-05, -2.2127e-04,  1.7776e-04,  1.4573e-04, -5.4994e-05,\n",
              "                        3.6697e-04,  1.9702e-04, -2.7578e-05, -6.1506e-05, -6.1456e-06,\n",
              "                        2.9156e-04,  2.6492e-04,  1.9228e-04, -2.1912e-05,  3.2806e-05,\n",
              "                        2.9702e-05, -3.3602e-04, -3.2825e-04,  1.6992e-05, -6.1763e-05,\n",
              "                       -2.1102e-05,  5.2941e-05, -2.5759e-04,  1.6362e-05, -7.0703e-05,\n",
              "                        4.1383e-05, -6.9334e-05, -8.2299e-05, -3.9453e-03,  7.1152e-03,\n",
              "                        2.5076e-03,  5.8807e-03,  2.7303e-03, -2.7385e-03,  7.7685e-03,\n",
              "                        1.6047e-03,  6.9786e-04,  6.8977e-03, -2.9459e-03, -2.5756e-03,\n",
              "                       -8.4672e-04,  8.2576e-03, -1.2230e-02, -2.9931e-04, -3.8159e-03,\n",
              "                       -1.3992e-03,  4.7788e-03, -3.6738e-03, -8.7570e-04, -1.6404e-03,\n",
              "                        1.6840e-03, -2.4020e-03,  4.1096e-04,  1.4514e-03, -1.3395e-03,\n",
              "                        1.9802e-03,  2.2726e-03, -4.0623e-03,  3.6790e-03, -3.7424e-03,\n",
              "                       -4.2710e-03, -9.4882e-04, -8.4345e-04, -2.4408e-03, -8.6991e-04,\n",
              "                        4.7110e-04,  9.0986e-04, -6.3612e-03,  2.5582e-03, -1.7597e-03,\n",
              "                        9.9680e-04, -5.0808e-03,  2.9533e-04, -4.7559e-03,  3.2318e-03,\n",
              "                        5.2261e-04, -1.5712e-04,  4.1846e-03,  1.9752e-03, -1.8703e-03,\n",
              "                        8.4844e-04, -3.3504e-03, -5.3474e-03, -9.4158e-04, -5.7057e-03,\n",
              "                       -8.3663e-04, -5.0671e-03,  1.9766e-03,  6.0835e-03, -3.0951e-03,\n",
              "                       -3.5338e-04,  8.0911e-04], device='cuda:0')),\n",
              "              ('transformer.resblocks.2.attn.out_proj.weight',\n",
              "               tensor([[-0.0070, -0.0669, -0.1175,  ..., -0.0064,  0.0232, -0.0838],\n",
              "                       [ 0.0198, -0.0490,  0.0558,  ...,  0.0500,  0.0668, -0.0479],\n",
              "                       [ 0.0148,  0.0176,  0.0513,  ..., -0.0024,  0.1219, -0.0718],\n",
              "                       ...,\n",
              "                       [-0.0307, -0.0285,  0.0451,  ..., -0.0209, -0.1363, -0.0282],\n",
              "                       [ 0.0389, -0.0290,  0.0061,  ..., -0.0814, -0.1358,  0.0576],\n",
              "                       [-0.0928, -0.0153,  0.0343,  ..., -0.0884, -0.0692,  0.1218]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.attn.out_proj.bias',\n",
              "               tensor([-6.4676e-03, -5.7519e-03, -1.3145e-04, -7.9798e-03,  1.5797e-03,\n",
              "                       -5.5653e-03, -1.5842e-03,  2.3748e-03,  2.4300e-03,  4.2583e-03,\n",
              "                        5.4783e-04,  6.9987e-03,  2.6830e-03,  4.5577e-03,  2.1877e-03,\n",
              "                       -7.6038e-05, -6.9346e-03, -5.9515e-03,  1.3711e-03,  7.2204e-04,\n",
              "                        1.2448e-03,  3.0929e-03, -1.4432e-03, -1.1924e-03,  2.8913e-03,\n",
              "                        1.8050e-03,  5.6313e-03, -4.5009e-03,  4.6786e-03, -5.0953e-03,\n",
              "                       -1.0786e-03,  8.5771e-05, -2.2310e-04,  4.7740e-03, -4.4312e-03,\n",
              "                        2.2658e-03,  4.2431e-03, -5.8079e-03, -1.9769e-03,  7.4556e-04,\n",
              "                       -6.4893e-03,  3.4226e-03, -3.1181e-03, -2.0515e-03, -2.4353e-03,\n",
              "                       -7.3137e-04,  2.0389e-04,  2.3009e-03, -2.0902e-03,  6.2339e-03,\n",
              "                        8.0297e-03,  3.5965e-03,  3.7988e-03, -4.5789e-03,  3.4353e-03,\n",
              "                       -2.8718e-03,  9.4936e-04, -5.2298e-03,  1.1336e-03,  5.9440e-03,\n",
              "                        7.1308e-03,  3.3428e-04,  5.1601e-03, -5.2495e-04], device='cuda:0')),\n",
              "              ('transformer.resblocks.2.ln_1.weight',\n",
              "               tensor([1.0239, 1.0172, 1.0053, 1.0335, 1.0442, 0.9994, 0.9892, 1.0362, 0.9957,\n",
              "                       0.9988, 1.0388, 1.0129, 1.0033, 1.0355, 1.0162, 1.0303, 1.0581, 1.0613,\n",
              "                       1.0536, 1.0168, 1.0308, 1.0044, 1.0483, 1.0360, 1.0509, 0.9998, 1.0403,\n",
              "                       1.0121, 1.0024, 1.0383, 1.0243, 1.0270, 1.0509, 1.0081, 1.0261, 1.0292,\n",
              "                       1.0058, 1.0300, 1.0096, 1.0039, 1.0128, 1.0448, 1.0312, 0.9997, 1.0207,\n",
              "                       1.0779, 1.0345, 1.0395, 1.0112, 1.0295, 1.0394, 1.0263, 1.0574, 1.0365,\n",
              "                       0.9915, 1.0345, 1.0229, 0.9972, 1.0590, 1.0133, 1.0113, 1.0257, 1.0472,\n",
              "                       1.0263], device='cuda:0')),\n",
              "              ('transformer.resblocks.2.ln_1.bias',\n",
              "               tensor([-0.0037,  0.0523, -0.0022,  0.0018, -0.0296, -0.0159, -0.0045, -0.0250,\n",
              "                       -0.0002, -0.0092,  0.0254, -0.0167, -0.0007, -0.0135, -0.0197,  0.0176,\n",
              "                        0.0366,  0.0431, -0.0501, -0.0105,  0.0156,  0.0073,  0.0429,  0.0163,\n",
              "                       -0.0206, -0.0172, -0.0438,  0.0018, -0.0202,  0.0273, -0.0084,  0.0049,\n",
              "                       -0.0169,  0.0087,  0.0066, -0.0076,  0.0047,  0.0207,  0.0177,  0.0100,\n",
              "                       -0.0083, -0.0213,  0.0012,  0.0100, -0.0060,  0.0045, -0.0081, -0.0179,\n",
              "                       -0.0151, -0.0079, -0.0341,  0.0358, -0.0445,  0.0158, -0.0165, -0.0108,\n",
              "                       -0.0230,  0.0029, -0.0608,  0.0146,  0.0096, -0.0022,  0.0258,  0.0068],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.mlp.0.weight',\n",
              "               tensor([[ 0.0557,  0.0988, -0.0817,  ...,  0.0847,  0.0404,  0.0831],\n",
              "                       [-0.1381, -0.0857,  0.0480,  ...,  0.0425,  0.0758, -0.0693],\n",
              "                       [-0.0102, -0.1002, -0.0045,  ...,  0.0950, -0.0673, -0.0529],\n",
              "                       ...,\n",
              "                       [-0.0484,  0.0628,  0.0652,  ...,  0.0583,  0.0073,  0.0281],\n",
              "                       [-0.0355, -0.0899, -0.0058,  ...,  0.1313,  0.0335, -0.0270],\n",
              "                       [ 0.0360, -0.0089,  0.0936,  ..., -0.0535,  0.0233, -0.0852]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.mlp.0.bias',\n",
              "               tensor([ 0.0377, -0.0296,  0.0598, -0.1105,  0.0591,  0.0698,  0.1107, -0.0725,\n",
              "                        0.1059, -0.0385, -0.0590, -0.0063,  0.0106, -0.0933,  0.0952,  0.0216,\n",
              "                        0.0371, -0.0947,  0.1063,  0.0145, -0.0612,  0.0924, -0.0152, -0.0688,\n",
              "                       -0.0531,  0.1088, -0.0659, -0.0807,  0.0505,  0.0264,  0.0029, -0.0880,\n",
              "                        0.0461,  0.0321, -0.0293,  0.0888, -0.0129, -0.1176,  0.0796,  0.0728,\n",
              "                        0.0320, -0.0779,  0.0194, -0.0104, -0.1059, -0.0478, -0.0293, -0.0600,\n",
              "                       -0.0300,  0.0776,  0.0724, -0.1024,  0.1196,  0.0139, -0.0851,  0.0146,\n",
              "                       -0.1187,  0.0310, -0.0126,  0.0026, -0.0638,  0.0951, -0.0690,  0.1006,\n",
              "                       -0.0264, -0.0462, -0.0888,  0.0008, -0.0185,  0.0334,  0.0296,  0.0456,\n",
              "                       -0.0147,  0.0425, -0.0670, -0.0404, -0.0428,  0.1016,  0.0606, -0.0643,\n",
              "                       -0.0956,  0.0524,  0.0472,  0.0984, -0.0933,  0.1023,  0.1156, -0.0890,\n",
              "                       -0.0674,  0.0690,  0.0207,  0.0874, -0.0518, -0.1220, -0.1333, -0.1204,\n",
              "                       -0.1019, -0.1031, -0.0397,  0.1152, -0.0814, -0.0870,  0.0753,  0.0828,\n",
              "                        0.1083, -0.0717,  0.0618, -0.0315, -0.0175,  0.0059, -0.0381,  0.0928,\n",
              "                        0.0021, -0.0327,  0.0771, -0.0891, -0.0177, -0.0792, -0.1158,  0.0647,\n",
              "                        0.0163, -0.0941, -0.0310,  0.0556,  0.0558, -0.0693,  0.0547,  0.0370,\n",
              "                       -0.0937,  0.0813, -0.1300, -0.0030,  0.0352, -0.1106,  0.1209,  0.0194,\n",
              "                       -0.0292, -0.0272, -0.0276, -0.0834,  0.0535, -0.1050,  0.0951,  0.0972,\n",
              "                        0.0375, -0.0492,  0.0408, -0.0541, -0.0986,  0.0887, -0.0392,  0.1002,\n",
              "                       -0.0294, -0.1226,  0.0245, -0.1307,  0.0474, -0.0114,  0.0679,  0.1073,\n",
              "                        0.0788, -0.1137,  0.0435,  0.0243,  0.0714, -0.1163,  0.0648,  0.0178,\n",
              "                       -0.0423, -0.0981, -0.0284, -0.0429, -0.0451,  0.1188,  0.1211, -0.0047,\n",
              "                       -0.1083, -0.1168,  0.0107,  0.0741,  0.0325, -0.0956,  0.1009, -0.0159,\n",
              "                        0.1046, -0.0474, -0.0031,  0.0809, -0.1142, -0.0528,  0.0358,  0.0903,\n",
              "                       -0.0467, -0.1064,  0.0826, -0.0449,  0.0965, -0.0549,  0.0161,  0.0743,\n",
              "                        0.1047,  0.0427,  0.0987,  0.0472, -0.0960, -0.0803, -0.1208, -0.0113,\n",
              "                        0.0680, -0.0364,  0.1151,  0.0201, -0.0072, -0.1187, -0.0953,  0.0697,\n",
              "                        0.0692,  0.0618,  0.0222, -0.1009,  0.0943,  0.1181, -0.0557, -0.0544,\n",
              "                       -0.1217, -0.0927, -0.1220,  0.0097,  0.0433, -0.0879, -0.0990, -0.1016,\n",
              "                       -0.1225, -0.0884, -0.0108,  0.0630,  0.0954, -0.0232, -0.0684, -0.0624,\n",
              "                       -0.0735, -0.1255, -0.1020,  0.0906, -0.0078, -0.0856,  0.0608, -0.0488,\n",
              "                        0.0069,  0.0255,  0.0947, -0.0763, -0.0730, -0.0653, -0.0889,  0.1061],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.mlp.2.weight',\n",
              "               tensor([[ 0.0507, -0.0361,  0.0072,  ..., -0.0623,  0.0241, -0.0126],\n",
              "                       [-0.0134, -0.0007,  0.0107,  ..., -0.0420,  0.0389, -0.0429],\n",
              "                       [-0.0585, -0.0268,  0.0111,  ..., -0.0654, -0.0295, -0.0121],\n",
              "                       ...,\n",
              "                       [ 0.0192,  0.0344, -0.0030,  ...,  0.0942,  0.0216, -0.0338],\n",
              "                       [ 0.0004,  0.0485,  0.0461,  ..., -0.0398,  0.0710, -0.0379],\n",
              "                       [-0.0430, -0.0478, -0.0218,  ..., -0.0100, -0.0043, -0.0328]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.mlp.2.bias',\n",
              "               tensor([-0.0404, -0.0633, -0.0452, -0.0330,  0.0401, -0.0563,  0.0444,  0.0320,\n",
              "                       -0.0395, -0.0223, -0.0426, -0.0467, -0.0071,  0.0020,  0.0434,  0.0137,\n",
              "                        0.0391,  0.0263,  0.0568,  0.0261, -0.0370,  0.0232, -0.0377,  0.0489,\n",
              "                        0.0387,  0.0037,  0.0248, -0.0564, -0.0497,  0.0283,  0.0246, -0.0028,\n",
              "                       -0.0204,  0.0507, -0.0128, -0.0049, -0.0096,  0.0501, -0.0463, -0.0161,\n",
              "                        0.0552, -0.0399, -0.0488, -0.0252,  0.0438,  0.0517, -0.0007,  0.0447,\n",
              "                        0.0256, -0.0151,  0.0545,  0.0254,  0.0245,  0.0121, -0.0384,  0.0217,\n",
              "                       -0.0008, -0.0371, -0.0175,  0.0579, -0.0359,  0.0313,  0.0290, -0.0299],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.2.ln_2.weight',\n",
              "               tensor([1.0046, 0.9990, 0.9983, 1.0153, 1.0078, 1.0046, 1.0006, 1.0141, 0.9939,\n",
              "                       0.9775, 0.9936, 0.9862, 0.9967, 1.0006, 0.9984, 0.9897, 1.0183, 0.9752,\n",
              "                       0.9938, 1.0121, 1.0117, 1.0139, 0.9895, 0.9786, 1.0024, 1.0245, 1.0149,\n",
              "                       1.0261, 1.0302, 0.9561, 1.0286, 1.0010, 1.0274, 1.0016, 0.9955, 1.0040,\n",
              "                       0.9821, 0.9941, 0.9987, 1.0103, 0.9865, 0.9887, 1.0207, 0.9993, 1.0176,\n",
              "                       1.0564, 1.0096, 1.0301, 1.0180, 1.0084, 0.9858, 1.0375, 1.0066, 1.0131,\n",
              "                       1.0072, 1.0023, 0.9934, 1.0036, 1.0015, 1.0193, 1.0271, 1.0083, 0.9864,\n",
              "                       1.0121], device='cuda:0')),\n",
              "              ('transformer.resblocks.2.ln_2.bias',\n",
              "               tensor([-5.9484e-03, -2.0972e-02,  9.0078e-03, -1.4237e-02, -3.2569e-03,\n",
              "                       -4.9438e-03,  2.3054e-04,  3.8831e-04, -8.3278e-03, -1.9446e-02,\n",
              "                       -1.6506e-02,  7.7581e-03,  2.0214e-03,  4.0228e-03,  1.8288e-03,\n",
              "                       -6.3668e-03, -7.2186e-03, -1.4863e-02,  9.4744e-03,  1.9838e-03,\n",
              "                       -2.2358e-03,  1.7194e-03, -4.2177e-03, -4.7487e-03,  7.8433e-03,\n",
              "                        1.1990e-02, -2.9740e-03, -2.3913e-03,  2.0788e-03, -2.1036e-02,\n",
              "                        1.1204e-02, -8.5831e-04, -6.2126e-03,  7.6654e-03, -1.9439e-03,\n",
              "                       -1.1521e-02,  1.2688e-02, -2.0029e-02, -1.1064e-02, -4.2389e-03,\n",
              "                       -9.9959e-03,  1.0472e-02,  3.1268e-03,  3.0361e-03, -3.0646e-03,\n",
              "                        1.0305e-03, -1.7595e-03, -1.0692e-02,  3.5879e-03,  2.3745e-03,\n",
              "                        7.7014e-03,  5.9693e-03,  2.8852e-03,  2.4992e-03, -1.4234e-03,\n",
              "                       -8.9723e-05,  4.5014e-03, -1.4299e-03,  1.3683e-02,  2.5539e-03,\n",
              "                        4.3147e-03, -6.5723e-03, -5.5234e-03, -8.6555e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.3.attn.in_proj_weight',\n",
              "               tensor([[ 0.0827,  0.0775,  0.0356,  ..., -0.1708,  0.1478,  0.0815],\n",
              "                       [-0.0714,  0.1301,  0.0488,  ..., -0.0342, -0.1322,  0.1182],\n",
              "                       [-0.0290, -0.0893, -0.1645,  ..., -0.0947,  0.1506,  0.0516],\n",
              "                       ...,\n",
              "                       [-0.0511,  0.0985, -0.0419,  ...,  0.0330, -0.0327, -0.0822],\n",
              "                       [-0.1114, -0.0690,  0.0319,  ...,  0.0464, -0.0259,  0.1226],\n",
              "                       [ 0.1509,  0.1158, -0.0982,  ..., -0.0384, -0.0072, -0.1206]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.attn.in_proj_bias',\n",
              "               tensor([ 1.0127e-02, -8.5438e-03,  1.4982e-02,  2.0708e-03,  2.6002e-02,\n",
              "                        1.7187e-03,  2.2586e-03,  7.4285e-03,  2.1712e-02,  2.1008e-03,\n",
              "                        1.1587e-02, -9.2262e-03, -4.5836e-03, -1.5580e-02,  2.7517e-03,\n",
              "                        8.8913e-03, -3.4949e-02,  5.7257e-03, -5.3795e-02,  3.8871e-02,\n",
              "                        1.1710e-02,  4.5124e-02,  2.4643e-02, -2.4106e-02,  9.4512e-03,\n",
              "                        1.5880e-02,  3.8953e-02, -1.6250e-02, -1.1361e-02, -4.9216e-02,\n",
              "                       -1.1075e-02,  1.6773e-02,  2.6321e-02, -2.2793e-02,  8.2114e-03,\n",
              "                        1.3278e-02, -3.4450e-02,  1.1444e-02, -1.3468e-02, -4.7042e-02,\n",
              "                       -5.6984e-03,  7.8923e-03,  2.3115e-04,  6.6808e-03,  6.4099e-03,\n",
              "                       -1.1351e-02, -1.4690e-02,  1.1478e-02,  2.1258e-02, -3.0702e-03,\n",
              "                       -1.0657e-03, -2.6494e-02,  1.3196e-02,  1.9074e-02,  6.8677e-03,\n",
              "                       -2.8304e-02,  5.0227e-03,  1.5209e-02, -2.5304e-02, -1.5368e-03,\n",
              "                        2.2707e-02,  3.3294e-02,  2.2227e-02, -7.7366e-03,  1.6169e-04,\n",
              "                        1.2003e-04, -1.9741e-04,  2.3152e-04, -8.3997e-06, -1.1106e-04,\n",
              "                       -1.5297e-05,  1.3245e-04, -2.6202e-04,  1.5953e-04, -1.7387e-05,\n",
              "                       -1.5805e-04, -4.5813e-05, -3.1982e-04, -1.1499e-05,  1.2759e-04,\n",
              "                       -4.4813e-04,  4.7776e-05,  6.0556e-04, -6.2988e-04, -1.3625e-04,\n",
              "                        5.1096e-05,  2.2297e-04,  1.8245e-04,  2.5592e-05,  9.6860e-05,\n",
              "                        3.2831e-04,  1.7930e-04, -1.0026e-04,  1.5635e-03,  2.4306e-04,\n",
              "                        5.0693e-04, -6.5343e-04, -7.9155e-05,  9.3023e-05,  1.4165e-04,\n",
              "                       -5.7095e-04, -6.9970e-05, -6.7391e-05,  2.9852e-04,  6.1140e-05,\n",
              "                       -7.5340e-05, -1.0933e-05,  4.1180e-04,  9.3093e-06, -7.4350e-04,\n",
              "                       -3.5155e-04,  3.7141e-05,  2.3439e-04, -2.6459e-05, -1.9366e-04,\n",
              "                       -7.5526e-05,  1.1901e-04,  7.2400e-04,  1.3920e-04, -1.0916e-04,\n",
              "                       -9.5474e-04,  5.1915e-04, -3.0977e-04,  1.9405e-04,  2.5805e-04,\n",
              "                        4.5321e-06,  9.6055e-04,  5.1727e-04, -6.0854e-03, -5.0902e-03,\n",
              "                        4.9291e-03,  4.6903e-04,  6.2977e-03,  5.8106e-03, -1.8908e-03,\n",
              "                        2.5505e-03, -7.0912e-03, -1.5059e-03, -4.0433e-04,  1.2247e-03,\n",
              "                        3.3582e-03, -1.8510e-03, -3.3709e-03,  2.1567e-03, -2.5452e-03,\n",
              "                        2.1899e-03,  5.9582e-03,  5.9740e-04,  2.9791e-03,  1.4923e-03,\n",
              "                        3.4385e-04,  2.8935e-03,  7.0088e-04,  1.2136e-03,  2.5221e-03,\n",
              "                        1.8222e-03,  9.6937e-04,  1.8921e-03, -4.4557e-03, -5.5466e-03,\n",
              "                       -1.7021e-03, -2.4313e-03,  3.7745e-03, -5.7524e-04,  4.9110e-03,\n",
              "                        1.6359e-03,  2.3056e-03,  2.0206e-03, -5.5048e-04, -7.5398e-06,\n",
              "                        9.4437e-03, -7.9581e-04,  3.4871e-03,  6.6530e-04,  1.3887e-03,\n",
              "                       -2.2493e-03, -2.2558e-03, -4.0776e-03,  7.1189e-03,  2.6981e-03,\n",
              "                       -2.8979e-03, -2.2536e-03,  6.4991e-03,  1.7629e-03,  1.0212e-02,\n",
              "                       -7.6908e-03, -1.3840e-05,  3.9260e-04,  1.9412e-03, -1.4307e-03,\n",
              "                        6.2924e-03,  5.1889e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.3.attn.out_proj.weight',\n",
              "               tensor([[ 0.0963, -0.0716,  0.1100,  ..., -0.0559,  0.1168, -0.1096],\n",
              "                       [ 0.1141,  0.0933,  0.1261,  ..., -0.0904,  0.0672, -0.0429],\n",
              "                       [ 0.0870, -0.0983, -0.0764,  ...,  0.1192, -0.1163,  0.0149],\n",
              "                       ...,\n",
              "                       [-0.0836, -0.0253,  0.0247,  ...,  0.0795,  0.0545, -0.0367],\n",
              "                       [ 0.0844,  0.0146, -0.0630,  ...,  0.0541,  0.0103, -0.0863],\n",
              "                       [-0.0677, -0.0663,  0.0645,  ...,  0.0788,  0.0465,  0.0031]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.attn.out_proj.bias',\n",
              "               tensor([ 1.0949e-03,  3.5367e-03, -4.1750e-03, -3.6737e-03,  4.8437e-03,\n",
              "                       -5.7124e-03,  2.7764e-03,  3.6175e-03,  3.4816e-03,  1.5621e-03,\n",
              "                       -5.2331e-03,  1.0204e-02, -9.9418e-04,  6.1841e-03,  1.5650e-04,\n",
              "                        6.3505e-04, -5.1221e-03, -3.8670e-03, -3.6584e-04, -5.5736e-04,\n",
              "                       -1.7948e-03,  8.0382e-04,  8.1462e-05,  8.5999e-04,  8.4522e-03,\n",
              "                        5.1381e-03,  5.6581e-03, -6.1350e-03,  6.6361e-03, -9.1096e-05,\n",
              "                       -1.7457e-03, -2.2812e-03,  1.1000e-03,  5.9920e-04, -7.5263e-03,\n",
              "                        3.2237e-03, -3.4819e-03, -4.0780e-03,  1.6073e-03,  1.8859e-03,\n",
              "                       -8.7828e-03, -3.7827e-05, -3.1064e-03,  3.6554e-04,  6.8220e-03,\n",
              "                       -3.3236e-03, -4.8857e-03,  2.9847e-03, -1.2475e-03,  6.0789e-03,\n",
              "                        2.4160e-03, -3.2388e-03,  5.6358e-03, -2.6906e-03,  3.9757e-04,\n",
              "                        1.8394e-03,  3.2050e-04, -4.2583e-03, -1.2704e-03,  7.4260e-04,\n",
              "                       -6.6573e-04,  2.6976e-03, -3.9373e-03,  7.1813e-04], device='cuda:0')),\n",
              "              ('transformer.resblocks.3.ln_1.weight',\n",
              "               tensor([1.0150, 0.9940, 1.0052, 1.0036, 1.0112, 1.0415, 1.0219, 1.0293, 1.0453,\n",
              "                       1.0400, 1.0394, 1.0278, 1.0598, 1.0151, 1.0243, 1.0321, 0.9808, 1.0141,\n",
              "                       1.0311, 1.0424, 1.0203, 1.0198, 1.0331, 1.0079, 1.0499, 1.0001, 1.0256,\n",
              "                       1.0791, 0.9867, 1.0080, 1.0316, 1.0159, 1.0207, 0.9885, 1.0374, 1.0317,\n",
              "                       1.0067, 1.0448, 1.0153, 1.0003, 1.0331, 1.0128, 1.0280, 1.0453, 1.0361,\n",
              "                       0.9992, 1.0400, 1.0104, 1.0534, 1.0356, 1.0198, 1.0531, 1.0289, 0.9909,\n",
              "                       1.0152, 1.0552, 1.0466, 1.0365, 1.0455, 1.0321, 1.0328, 1.0200, 1.0439,\n",
              "                       1.0284], device='cuda:0')),\n",
              "              ('transformer.resblocks.3.ln_1.bias',\n",
              "               tensor([-0.0090, -0.0164,  0.0235, -0.0025,  0.0074,  0.0110, -0.0115, -0.0164,\n",
              "                        0.0302,  0.0454,  0.0365, -0.0236,  0.0485, -0.0167,  0.0159,  0.0266,\n",
              "                        0.0140,  0.0237, -0.0344,  0.0316,  0.0266,  0.0075,  0.0234, -0.0100,\n",
              "                       -0.0368, -0.0010, -0.0027,  0.0285, -0.0161,  0.0104, -0.0003, -0.0019,\n",
              "                        0.0194, -0.0064,  0.0170, -0.0009, -0.0150,  0.0183,  0.0133,  0.0237,\n",
              "                        0.0354, -0.0234, -0.0359, -0.0279, -0.0347, -0.0477, -0.0146,  0.0136,\n",
              "                       -0.0209, -0.0232, -0.0080,  0.0229, -0.0163, -0.0074,  0.0041, -0.0330,\n",
              "                       -0.0317, -0.0286, -0.0392,  0.0313,  0.0256, -0.0179,  0.0349,  0.0266],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.mlp.0.weight',\n",
              "               tensor([[-0.0620,  0.0770,  0.0575,  ..., -0.0693, -0.1001,  0.0226],\n",
              "                       [-0.0076, -0.1298,  0.0507,  ...,  0.0232, -0.0599, -0.0136],\n",
              "                       [ 0.0515,  0.1050,  0.0785,  ...,  0.1162, -0.0102, -0.0511],\n",
              "                       ...,\n",
              "                       [-0.0752,  0.0716, -0.1147,  ...,  0.0091,  0.0982, -0.0817],\n",
              "                       [-0.0199,  0.0828,  0.0204,  ..., -0.0689,  0.0976,  0.0126],\n",
              "                       [-0.0257,  0.1253,  0.1100,  ..., -0.1425,  0.0814,  0.0733]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.mlp.0.bias',\n",
              "               tensor([-0.0828, -0.0657, -0.1334,  0.0366,  0.1164,  0.0655, -0.0749, -0.1195,\n",
              "                        0.0874, -0.1224,  0.0628,  0.0689,  0.1109, -0.0919, -0.1256, -0.0713,\n",
              "                        0.0610,  0.0325, -0.1026, -0.1153, -0.0382, -0.0105, -0.0912,  0.1144,\n",
              "                       -0.1302,  0.0980, -0.0185,  0.0641,  0.0341,  0.1141, -0.1177, -0.0671,\n",
              "                       -0.1294,  0.1115, -0.0788,  0.0342,  0.0788,  0.0828, -0.0664,  0.0136,\n",
              "                        0.0649, -0.0171, -0.0848, -0.0364, -0.0243, -0.0932,  0.0508,  0.0288,\n",
              "                        0.0880, -0.0270, -0.1032, -0.0507, -0.0203, -0.1233, -0.0772,  0.0341,\n",
              "                        0.0087, -0.0311, -0.0375,  0.0699, -0.0070, -0.1259,  0.0616, -0.1244,\n",
              "                        0.0914, -0.0044, -0.1078, -0.0359,  0.0057, -0.0185,  0.0249,  0.0536,\n",
              "                        0.1095, -0.0950, -0.0514, -0.0730, -0.0536, -0.0355,  0.0615, -0.0920,\n",
              "                       -0.0821,  0.0324,  0.0263,  0.0560, -0.0390,  0.1279,  0.0776, -0.0249,\n",
              "                       -0.0594, -0.1279, -0.0717,  0.0685, -0.0092, -0.0756, -0.0545,  0.0653,\n",
              "                        0.1044, -0.0277, -0.0619,  0.0431,  0.0819,  0.0560,  0.0370,  0.0881,\n",
              "                        0.0918, -0.0779, -0.0474, -0.0939,  0.1086,  0.0217,  0.0178, -0.0720,\n",
              "                        0.0630, -0.0322, -0.0223, -0.1224, -0.1105,  0.0484, -0.0389,  0.1011,\n",
              "                       -0.1044,  0.0813, -0.0223, -0.0178,  0.0039,  0.0447,  0.0899, -0.1273,\n",
              "                        0.0087,  0.0177, -0.0662,  0.0474, -0.0390,  0.0840, -0.0132, -0.0316,\n",
              "                        0.1040, -0.0253, -0.0399, -0.1247, -0.0997,  0.0080, -0.0523, -0.1221,\n",
              "                       -0.0215,  0.0599, -0.0800,  0.0403, -0.0463, -0.0806,  0.0248,  0.0094,\n",
              "                       -0.0205, -0.0795, -0.1245, -0.0417, -0.0346, -0.0955,  0.1157, -0.0231,\n",
              "                       -0.1001, -0.0924, -0.0057, -0.1158,  0.0236, -0.0609, -0.0429, -0.0599,\n",
              "                        0.0927,  0.0550,  0.0868,  0.0494,  0.1053,  0.0209,  0.0997,  0.0828,\n",
              "                        0.0256, -0.0797, -0.1008,  0.0721, -0.0001, -0.0088,  0.0228,  0.0057,\n",
              "                       -0.1051,  0.0640,  0.0888, -0.0451, -0.0705,  0.0570, -0.0652,  0.0765,\n",
              "                       -0.0706, -0.0754,  0.0089, -0.0680,  0.0397, -0.0410, -0.0839,  0.0784,\n",
              "                        0.0778, -0.0694, -0.0776, -0.0490,  0.0345,  0.0456, -0.0369,  0.0385,\n",
              "                       -0.0684, -0.0047, -0.0300, -0.0507,  0.0050, -0.0954,  0.0884, -0.0848,\n",
              "                       -0.0483, -0.0904, -0.0968, -0.0049, -0.0962, -0.0984, -0.0219, -0.1128,\n",
              "                        0.0794, -0.0449,  0.0513,  0.0104, -0.1019,  0.0852, -0.1138,  0.1046,\n",
              "                        0.0670, -0.0655,  0.0964, -0.1025,  0.0987,  0.0301,  0.0003,  0.0107,\n",
              "                        0.0087,  0.0897, -0.0268,  0.0790,  0.0714,  0.0898,  0.0096,  0.0809,\n",
              "                        0.0681,  0.0804,  0.1046, -0.0016, -0.1312,  0.0313, -0.1224,  0.0714],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.mlp.2.weight',\n",
              "               tensor([[-0.0627, -0.0724, -0.0015,  ...,  0.0446,  0.0491,  0.0668],\n",
              "                       [ 0.0170, -0.0351, -0.0256,  ...,  0.0234,  0.0235, -0.0346],\n",
              "                       [-0.0343, -0.0182,  0.0520,  ...,  0.0367, -0.0064,  0.0410],\n",
              "                       ...,\n",
              "                       [-0.0809, -0.0422, -0.0354,  ..., -0.0267,  0.0106, -0.0027],\n",
              "                       [-0.0624, -0.0534,  0.0524,  ..., -0.0194, -0.0562, -0.0391],\n",
              "                       [-0.0601, -0.0233, -0.0014,  ..., -0.0274, -0.0172,  0.0395]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.mlp.2.bias',\n",
              "               tensor([-0.0554, -0.0316,  0.0370,  0.0306, -0.0485, -0.0028,  0.0542, -0.0019,\n",
              "                       -0.0382, -0.0391, -0.0038,  0.0048, -0.0387,  0.0671,  0.0324,  0.0586,\n",
              "                        0.0301,  0.0071, -0.0280, -0.0492,  0.0451, -0.0244,  0.0466, -0.0515,\n",
              "                        0.0209,  0.0523, -0.0014,  0.0507,  0.0493,  0.0048, -0.0625, -0.0474,\n",
              "                        0.0378, -0.0444, -0.0481,  0.0585,  0.0351, -0.0154,  0.0353, -0.0038,\n",
              "                       -0.0079,  0.0311, -0.0090, -0.0522, -0.0282, -0.0335,  0.0540, -0.0275,\n",
              "                       -0.0114, -0.0260,  0.0116, -0.0508,  0.0072,  0.0039,  0.0099, -0.0115,\n",
              "                        0.0491,  0.0528, -0.0125,  0.0368, -0.0172, -0.0198, -0.0194, -0.0044],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.3.ln_2.weight',\n",
              "               tensor([0.9882, 1.0116, 0.9846, 0.9995, 1.0051, 1.0001, 1.0025, 0.9803, 1.0021,\n",
              "                       1.0018, 0.9904, 0.9959, 1.0047, 0.9988, 0.9984, 1.0051, 1.0132, 0.9948,\n",
              "                       0.9968, 0.9996, 1.0054, 1.0162, 0.9956, 0.9923, 0.9901, 1.0314, 0.9987,\n",
              "                       1.0179, 1.0178, 1.0011, 1.0115, 1.0005, 1.0135, 1.0105, 1.0037, 0.9934,\n",
              "                       0.9847, 1.0064, 0.9969, 0.9954, 0.9963, 0.9929, 1.0319, 0.9900, 0.9960,\n",
              "                       1.0228, 0.9884, 1.0182, 1.0053, 0.9945, 1.0034, 1.0005, 0.9699, 1.0046,\n",
              "                       0.9771, 0.9933, 0.9778, 1.0018, 0.9875, 0.9889, 1.0095, 1.0266, 1.0058,\n",
              "                       0.9950], device='cuda:0')),\n",
              "              ('transformer.resblocks.3.ln_2.bias',\n",
              "               tensor([-1.9085e-04, -6.5680e-04, -1.5313e-02,  1.5421e-02,  2.7995e-03,\n",
              "                        7.5269e-03, -1.0177e-03,  1.4620e-02, -1.0376e-02, -4.6673e-03,\n",
              "                       -2.1144e-02,  1.2383e-02, -6.2250e-03,  2.0402e-02, -9.6196e-03,\n",
              "                        5.3918e-03, -2.4496e-03,  3.0620e-03, -3.8435e-03, -6.7715e-03,\n",
              "                        8.6384e-03,  3.7204e-03, -7.8445e-03,  2.8857e-03,  9.8553e-03,\n",
              "                       -1.8164e-03,  7.1475e-03,  1.4037e-03,  4.4760e-03, -7.3816e-03,\n",
              "                        7.7400e-03,  5.9482e-03,  6.4087e-03,  4.8496e-04, -7.0184e-03,\n",
              "                        1.8769e-02,  1.7933e-02, -3.6387e-03,  3.9359e-03,  3.0338e-03,\n",
              "                       -1.2881e-02,  1.4546e-02,  4.3235e-03,  1.6221e-02,  2.0367e-02,\n",
              "                        5.6560e-03, -7.8851e-03, -5.1329e-03,  8.4413e-04,  1.7892e-02,\n",
              "                        1.6959e-05, -1.4937e-02,  2.8867e-02, -1.2775e-03, -4.4585e-03,\n",
              "                        1.3384e-02,  9.3059e-03,  3.9362e-03,  8.6997e-03, -6.6315e-04,\n",
              "                        1.9210e-03,  3.0130e-03, -1.4891e-02, -4.7042e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.4.attn.in_proj_weight',\n",
              "               tensor([[-0.0236, -0.1001, -0.0258,  ...,  0.1400, -0.0568, -0.1211],\n",
              "                       [-0.0484,  0.1168,  0.0918,  ..., -0.1231,  0.0267,  0.0425],\n",
              "                       [ 0.1612,  0.0782,  0.1496,  ...,  0.0928,  0.1553,  0.1521],\n",
              "                       ...,\n",
              "                       [-0.1412,  0.0603,  0.0027,  ...,  0.0786,  0.0780, -0.0604],\n",
              "                       [-0.0662, -0.0174, -0.1438,  ...,  0.1601,  0.0678, -0.0378],\n",
              "                       [-0.1335, -0.1160,  0.0537,  ...,  0.0410,  0.0077, -0.0981]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.attn.in_proj_bias',\n",
              "               tensor([-8.3788e-03,  1.9164e-02,  1.5831e-02, -1.5692e-02,  8.4042e-03,\n",
              "                       -1.6706e-02, -5.3370e-03,  4.8310e-03, -2.5965e-02, -4.7807e-04,\n",
              "                        3.3966e-02,  3.3703e-03, -2.2493e-02, -2.3643e-02,  3.7522e-02,\n",
              "                       -4.0929e-03,  7.2623e-03,  4.9224e-03,  1.1190e-02,  2.4216e-02,\n",
              "                        1.5966e-02, -2.4098e-02,  9.4555e-03,  1.4389e-02, -4.7605e-03,\n",
              "                       -3.3563e-02, -1.9492e-02, -4.9103e-02, -5.9565e-02, -9.7360e-03,\n",
              "                       -1.4336e-02,  8.9134e-03, -1.1498e-02, -3.5747e-02, -2.1187e-02,\n",
              "                       -1.8659e-02,  1.8270e-02,  3.3664e-02, -2.7765e-02, -1.4885e-02,\n",
              "                        1.7235e-02, -3.5102e-03,  3.3325e-02, -7.3781e-03,  7.4004e-03,\n",
              "                       -2.0601e-02, -6.8129e-03,  9.7855e-03, -1.5524e-02,  1.4946e-03,\n",
              "                       -1.4105e-02, -5.7996e-03,  2.4425e-02, -1.4358e-02,  1.1035e-02,\n",
              "                       -1.5045e-02, -2.0518e-03, -1.6982e-02,  2.9463e-02,  4.0133e-02,\n",
              "                        1.3330e-02,  1.4947e-02, -1.6861e-02, -1.5473e-02,  6.2543e-04,\n",
              "                       -1.5561e-03, -1.4556e-03,  1.6653e-03,  1.0163e-04,  2.9247e-04,\n",
              "                        3.2949e-04, -3.7091e-04,  9.4931e-05,  4.0272e-04,  3.5446e-04,\n",
              "                        1.6269e-04,  3.7409e-04,  6.1698e-04,  2.7801e-04, -2.4283e-04,\n",
              "                       -2.5866e-04, -3.1968e-05,  1.4930e-04, -1.1979e-04,  8.1190e-05,\n",
              "                        1.0717e-04,  9.1692e-05,  1.1029e-04,  9.7359e-05,  2.3897e-04,\n",
              "                       -4.5623e-04, -8.7438e-04, -4.5936e-05, -7.4393e-05, -3.1162e-05,\n",
              "                       -1.6994e-04,  6.3781e-05, -3.0097e-04, -2.4889e-04, -1.0609e-04,\n",
              "                        6.1016e-05, -1.1502e-04, -1.9939e-04,  2.0706e-04,  2.2904e-04,\n",
              "                       -2.1681e-04,  2.0015e-03,  6.3518e-05,  1.4272e-04,  6.5733e-04,\n",
              "                       -2.3141e-04,  3.0981e-04, -7.2019e-05, -5.7734e-05,  6.6273e-04,\n",
              "                        8.9251e-05, -4.6915e-05, -1.0889e-04,  1.9580e-04, -5.7732e-04,\n",
              "                       -2.7276e-04,  5.1200e-04, -1.4842e-04, -2.2586e-05,  1.7727e-04,\n",
              "                       -1.6889e-04, -2.5677e-04,  1.9352e-05, -3.2881e-04, -6.8481e-04,\n",
              "                       -4.4226e-03,  2.9644e-03, -3.8943e-04,  1.9837e-03, -5.2883e-03,\n",
              "                       -9.0035e-04,  4.0339e-03, -1.2651e-03, -1.4709e-03,  4.0816e-03,\n",
              "                        1.9892e-03, -3.3044e-03, -3.9960e-03,  6.3481e-03,  1.1954e-03,\n",
              "                       -2.3441e-03, -5.2418e-03,  5.0641e-03, -8.5842e-03,  4.8800e-03,\n",
              "                       -5.6334e-03,  4.3925e-04, -1.6909e-03,  2.6713e-03, -6.3919e-03,\n",
              "                        7.8735e-05, -2.1311e-03,  7.1787e-04, -2.5122e-03, -4.8436e-04,\n",
              "                       -1.5421e-04, -4.8757e-03, -5.7783e-04,  2.2991e-03,  6.1893e-03,\n",
              "                        5.5081e-03, -1.9194e-03,  3.3149e-03,  2.4418e-03, -5.8235e-04,\n",
              "                        1.5466e-03, -4.7669e-03, -2.3633e-04, -4.4093e-03,  4.4146e-03,\n",
              "                        1.1645e-03,  3.2947e-03,  6.1447e-03, -3.0785e-03,  6.8386e-03,\n",
              "                        6.9793e-03,  8.8539e-03, -1.2838e-02, -1.0413e-02,  3.5781e-03,\n",
              "                        3.6378e-03,  4.2799e-04,  1.3871e-04,  4.5236e-03,  2.9777e-03,\n",
              "                       -7.7649e-05, -2.6739e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.4.attn.out_proj.weight',\n",
              "               tensor([[-0.0320,  0.0890, -0.0192,  ...,  0.0024,  0.0786,  0.1293],\n",
              "                       [ 0.0775,  0.0788,  0.0812,  ...,  0.0471, -0.0815,  0.0043],\n",
              "                       [ 0.0380,  0.0324, -0.0228,  ..., -0.0044,  0.0169,  0.0028],\n",
              "                       ...,\n",
              "                       [-0.1104,  0.0607, -0.0533,  ...,  0.1508,  0.0983, -0.0650],\n",
              "                       [-0.0603,  0.0009, -0.0444,  ...,  0.0113,  0.0086,  0.0983],\n",
              "                       [-0.1057,  0.0562,  0.1203,  ...,  0.0195,  0.1232, -0.0588]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.attn.out_proj.bias',\n",
              "               tensor([-2.6534e-03,  3.3028e-04, -8.2458e-05, -2.7674e-03,  6.1996e-03,\n",
              "                       -1.0069e-02,  6.9441e-03,  4.2330e-03, -1.7760e-03, -6.8910e-03,\n",
              "                       -8.2368e-03,  1.7481e-02, -3.4892e-03,  6.2952e-03, -2.4700e-04,\n",
              "                       -2.6774e-04, -3.0476e-03, -3.1566e-03,  4.8023e-03,  5.2113e-03,\n",
              "                       -4.2908e-03, -1.9101e-03, -5.7845e-03,  6.7921e-03,  2.1120e-03,\n",
              "                        9.1771e-03,  9.3830e-03, -2.3831e-03, -3.9817e-03, -3.3250e-03,\n",
              "                       -4.2134e-03, -4.5280e-03, -1.7640e-03,  1.6134e-03, -5.3694e-03,\n",
              "                        3.2025e-03, -9.6287e-04, -3.2284e-03, -2.1142e-03, -2.2392e-04,\n",
              "                       -3.4061e-03,  4.3066e-03, -6.5336e-04, -1.1602e-03,  2.3024e-03,\n",
              "                       -2.4944e-03,  6.8800e-03,  4.9688e-03,  8.3964e-05,  9.4593e-04,\n",
              "                        3.7401e-03, -2.0995e-04,  2.4610e-03, -6.4465e-03, -2.5027e-03,\n",
              "                        6.6082e-03,  6.8851e-03, -6.4790e-03,  4.9656e-03, -4.0406e-04,\n",
              "                        5.2033e-03,  3.1511e-03, -6.0066e-03, -1.8175e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.4.ln_1.weight',\n",
              "               tensor([1.0298, 0.9874, 1.0171, 1.0023, 1.0005, 1.0418, 1.0135, 1.0248, 1.0377,\n",
              "                       1.0410, 1.0656, 1.0267, 1.0291, 1.0353, 1.0028, 1.0070, 1.0064, 1.0084,\n",
              "                       1.0410, 1.0073, 1.0338, 0.9979, 1.0474, 1.0482, 0.9988, 1.0278, 1.0282,\n",
              "                       1.0576, 1.0357, 1.0307, 1.0258, 1.0134, 1.0047, 1.0012, 0.9792, 0.9899,\n",
              "                       1.0220, 1.0342, 1.0331, 1.0240, 1.0385, 1.0322, 1.0470, 1.0370, 1.0033,\n",
              "                       1.0287, 1.0434, 1.0239, 1.0430, 1.0470, 1.0061, 1.0173, 1.0115, 1.0243,\n",
              "                       1.0117, 1.0249, 1.0419, 1.0127, 1.0338, 1.0461, 1.0085, 1.0179, 1.0404,\n",
              "                       1.0148], device='cuda:0')),\n",
              "              ('transformer.resblocks.4.ln_1.bias',\n",
              "               tensor([ 0.0295,  0.0110,  0.0184,  0.0027,  0.0154,  0.0253, -0.0048, -0.0188,\n",
              "                        0.0402,  0.0402,  0.0503, -0.0267,  0.0288, -0.0167,  0.0108,  0.0039,\n",
              "                        0.0029,  0.0095, -0.0419, -0.0317,  0.0239,  0.0088,  0.0300,  0.0032,\n",
              "                        0.0060,  0.0113, -0.0150, -0.0111,  0.0439,  0.0270,  0.0011,  0.0098,\n",
              "                        0.0015,  0.0005, -0.0020, -0.0258, -0.0183,  0.0195,  0.0338,  0.0101,\n",
              "                        0.0357, -0.0428, -0.0232, -0.0405, -0.0053, -0.0175, -0.0245, -0.0101,\n",
              "                       -0.0184, -0.0305, -0.0095,  0.0242, -0.0114,  0.0125,  0.0292, -0.0154,\n",
              "                       -0.0261, -0.0078, -0.0363,  0.0340, -0.0188, -0.0017,  0.0456,  0.0215],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.mlp.0.weight',\n",
              "               tensor([[-0.0085, -0.0623,  0.0245,  ...,  0.0936, -0.0086, -0.1069],\n",
              "                       [ 0.0204,  0.0469,  0.0950,  ..., -0.0409,  0.0717, -0.1074],\n",
              "                       [-0.0609,  0.0967, -0.0683,  ..., -0.1361, -0.0047, -0.0678],\n",
              "                       ...,\n",
              "                       [ 0.0246,  0.0178, -0.0479,  ...,  0.0193, -0.0490, -0.1110],\n",
              "                       [-0.0976,  0.1146, -0.0116,  ..., -0.0599,  0.0497, -0.0296],\n",
              "                       [ 0.0221,  0.0504,  0.0915,  ..., -0.0208,  0.0650,  0.0891]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.mlp.0.bias',\n",
              "               tensor([ 0.0978, -0.0886,  0.0776,  0.1022, -0.0589,  0.0319, -0.0093, -0.0051,\n",
              "                        0.0752,  0.0823,  0.0793,  0.0263, -0.1261,  0.0832, -0.1089, -0.1008,\n",
              "                       -0.0788,  0.1188,  0.1085, -0.0955, -0.0738,  0.0439, -0.0161,  0.0938,\n",
              "                        0.0919, -0.0934, -0.1169, -0.0465, -0.0251, -0.1132, -0.0628, -0.1089,\n",
              "                       -0.0894, -0.0668, -0.0867, -0.0206, -0.0482, -0.0493, -0.0402,  0.0816,\n",
              "                       -0.0088, -0.0314, -0.0638, -0.0395, -0.1276, -0.0669,  0.0464, -0.0821,\n",
              "                       -0.0506,  0.0012,  0.0021,  0.0194, -0.0288,  0.1067, -0.0002,  0.0163,\n",
              "                       -0.0222,  0.1056, -0.0857, -0.0200, -0.0977,  0.0008,  0.0390, -0.0622,\n",
              "                       -0.0754,  0.0377,  0.0056,  0.0756, -0.0777,  0.0194,  0.0981,  0.0801,\n",
              "                       -0.0859, -0.0787,  0.0455,  0.0665, -0.1011,  0.0218,  0.1098, -0.0134,\n",
              "                        0.1091,  0.0127,  0.1101,  0.0910, -0.0297, -0.1293,  0.1279, -0.0059,\n",
              "                        0.0194, -0.0392, -0.1282,  0.0363, -0.1071, -0.1096, -0.1183,  0.0943,\n",
              "                       -0.1233, -0.1301,  0.0724, -0.0523, -0.0933, -0.0714,  0.0705, -0.0774,\n",
              "                       -0.1133, -0.1235,  0.0027, -0.0366,  0.0714,  0.0167, -0.0876,  0.1204,\n",
              "                        0.0071,  0.0863,  0.0459,  0.0904,  0.0450, -0.1155,  0.1019, -0.0533,\n",
              "                        0.0137,  0.0373, -0.0351,  0.0714,  0.0037, -0.0984, -0.0360, -0.0672,\n",
              "                       -0.0944,  0.0824, -0.0674,  0.0788,  0.0574,  0.0359,  0.0333, -0.0120,\n",
              "                       -0.0709,  0.0662, -0.0009,  0.1037, -0.0334,  0.1156,  0.0625, -0.0177,\n",
              "                        0.1060, -0.0803, -0.0803,  0.0170, -0.0393, -0.1167, -0.0635,  0.0101,\n",
              "                        0.0437, -0.0251, -0.0212,  0.0771, -0.0055, -0.0356, -0.0416, -0.0444,\n",
              "                        0.0863,  0.0214, -0.0935, -0.0478, -0.0382, -0.0423,  0.0567,  0.1191,\n",
              "                        0.0453,  0.0117, -0.0290, -0.0310, -0.0637, -0.0455,  0.0828, -0.0439,\n",
              "                       -0.0415,  0.0353,  0.0523, -0.0935, -0.1142,  0.0714, -0.0499, -0.0987,\n",
              "                       -0.1098,  0.0418,  0.1178,  0.1067, -0.0008,  0.1044, -0.0721,  0.0910,\n",
              "                       -0.1107,  0.0100, -0.0486,  0.0385, -0.0356, -0.1010,  0.0672,  0.1140,\n",
              "                        0.0892, -0.1211,  0.0572,  0.0258,  0.1198, -0.1019, -0.1255,  0.0935,\n",
              "                        0.0686, -0.0886, -0.0704, -0.0663, -0.0132,  0.0691,  0.0154, -0.0978,\n",
              "                        0.0364, -0.1060, -0.0408,  0.0179,  0.0949, -0.0645, -0.0428, -0.0479,\n",
              "                        0.0981, -0.0242, -0.0378,  0.0436,  0.0691,  0.0789,  0.1089, -0.0050,\n",
              "                        0.0056,  0.0304, -0.0589, -0.0089, -0.0124, -0.0107,  0.0792,  0.1180,\n",
              "                        0.0062,  0.0932,  0.0831, -0.0109, -0.1232, -0.0292, -0.0336,  0.0887,\n",
              "                        0.0596,  0.0271, -0.0775, -0.0133, -0.1028, -0.1090,  0.0535, -0.0648],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.mlp.2.weight',\n",
              "               tensor([[-0.0133,  0.0560,  0.0485,  ..., -0.0467, -0.0227, -0.0596],\n",
              "                       [ 0.0044, -0.0166, -0.0332,  ...,  0.0137,  0.0121,  0.0486],\n",
              "                       [ 0.0100,  0.0642, -0.0333,  ...,  0.0211,  0.0391, -0.0232],\n",
              "                       ...,\n",
              "                       [-0.0208,  0.0297, -0.0322,  ...,  0.0364,  0.0276, -0.0037],\n",
              "                       [-0.0164, -0.0064, -0.0745,  ..., -0.0379,  0.0355,  0.0374],\n",
              "                       [ 0.0546,  0.0018, -0.0040,  ...,  0.0384, -0.0046, -0.0412]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.mlp.2.bias',\n",
              "               tensor([-0.0638,  0.0018,  0.0323,  0.0010, -0.0496,  0.0498, -0.0109, -0.0140,\n",
              "                        0.0381, -0.0301,  0.0166,  0.0268,  0.0107, -0.0432,  0.0386,  0.0594,\n",
              "                        0.0066, -0.0002,  0.0612,  0.0247,  0.0526,  0.0332, -0.0618,  0.0126,\n",
              "                       -0.0323, -0.0033,  0.0033,  0.0304, -0.0489, -0.0112, -0.0207,  0.0511,\n",
              "                        0.0407, -0.0225, -0.0586,  0.0054, -0.0208,  0.0531, -0.0394, -0.0458,\n",
              "                       -0.0179, -0.0245, -0.0073, -0.0329, -0.0539,  0.0369,  0.0207, -0.0044,\n",
              "                        0.0548,  0.0178, -0.0327,  0.0051, -0.0227, -0.0096, -0.0406, -0.0579,\n",
              "                        0.0294, -0.0187,  0.0272, -0.0602,  0.0035, -0.0217, -0.0302, -0.0254],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.4.ln_2.weight',\n",
              "               tensor([0.9874, 1.0192, 0.9932, 1.0145, 1.0077, 1.0087, 0.9839, 1.0070, 1.0066,\n",
              "                       0.9755, 0.9980, 1.0074, 1.0102, 1.0058, 1.0107, 1.0079, 1.0061, 0.9978,\n",
              "                       0.9919, 1.0040, 1.0065, 1.0042, 1.0076, 0.9836, 1.0132, 1.0097, 1.0005,\n",
              "                       1.0065, 1.0000, 0.9996, 1.0223, 1.0046, 0.9953, 1.0027, 1.0058, 0.9938,\n",
              "                       1.0043, 0.9978, 0.9932, 1.0032, 0.9904, 1.0051, 1.0226, 1.0046, 1.0041,\n",
              "                       1.0094, 0.9981, 1.0218, 1.0011, 1.0094, 0.9920, 1.0115, 1.0108, 0.9727,\n",
              "                       1.0096, 1.0057, 0.9896, 1.0015, 0.9917, 0.9938, 0.9798, 1.0051, 0.9917,\n",
              "                       1.0029], device='cuda:0')),\n",
              "              ('transformer.resblocks.4.ln_2.bias',\n",
              "               tensor([ 8.7330e-03,  2.3591e-03,  4.7411e-03, -4.1170e-03,  9.7017e-03,\n",
              "                       -4.9276e-03,  7.7071e-03,  2.8269e-03, -3.4025e-03, -1.2418e-02,\n",
              "                       -7.3200e-03,  3.2343e-03, -4.2958e-03,  3.3818e-03,  7.3715e-03,\n",
              "                        2.9568e-03, -6.6442e-03,  2.5052e-03,  2.3433e-02,  1.0567e-03,\n",
              "                        6.0282e-04, -3.0556e-03, -5.6546e-04, -2.8448e-03,  5.3984e-03,\n",
              "                        3.4502e-03,  1.0106e-02, -2.9257e-03, -3.3529e-03, -1.3373e-03,\n",
              "                        7.4364e-03, -6.5175e-03,  1.3322e-03,  1.0473e-02,  4.4814e-03,\n",
              "                        1.2542e-02,  7.9674e-03, -8.4642e-03, -4.0713e-03,  9.9331e-03,\n",
              "                       -1.1215e-02,  7.3621e-03, -8.1214e-04,  7.7791e-04, -6.3005e-04,\n",
              "                        1.0526e-05,  2.5291e-03,  1.5741e-03,  4.7077e-03,  8.2590e-03,\n",
              "                        3.9358e-03, -1.2649e-04,  6.6786e-04, -1.0529e-02,  1.1449e-03,\n",
              "                        1.4915e-02,  1.2173e-02,  1.7967e-02,  1.6841e-02,  8.1598e-03,\n",
              "                        1.4568e-02,  8.0530e-03, -7.3753e-03, -3.9503e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.5.attn.in_proj_weight',\n",
              "               tensor([[-0.0027, -0.0119,  0.1503,  ..., -0.0263,  0.0814,  0.0371],\n",
              "                       [ 0.1289, -0.1365,  0.0532,  ...,  0.1444,  0.0315,  0.0386],\n",
              "                       [ 0.0477, -0.0615, -0.0761,  ...,  0.1095, -0.1337,  0.0446],\n",
              "                       ...,\n",
              "                       [ 0.1090, -0.1463,  0.1020,  ...,  0.1106,  0.0192,  0.0297],\n",
              "                       [-0.0063, -0.0538, -0.0517,  ..., -0.0911,  0.0093, -0.0098],\n",
              "                       [ 0.1385, -0.1117, -0.0423,  ..., -0.0647, -0.0391, -0.1365]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.attn.in_proj_bias',\n",
              "               tensor([ 1.7682e-02, -6.2543e-02, -3.6611e-02,  1.0860e-02, -6.3697e-03,\n",
              "                        9.5467e-03, -3.7473e-02, -3.4501e-02,  1.1101e-02, -6.3732e-03,\n",
              "                        3.7845e-02,  4.5460e-03,  4.3039e-02,  2.2074e-02,  3.4020e-02,\n",
              "                       -9.6344e-03,  2.6262e-03, -2.7984e-02,  2.4739e-03,  3.0611e-02,\n",
              "                       -4.0427e-02, -1.8380e-02, -1.8374e-02, -1.4197e-02, -1.3274e-02,\n",
              "                        6.0192e-03, -8.5355e-03, -7.2662e-03, -2.0390e-02, -3.5808e-02,\n",
              "                       -6.8908e-03, -1.9122e-02,  2.3829e-02, -4.9188e-03, -9.3248e-03,\n",
              "                        1.7671e-02,  1.8130e-02,  1.6743e-02, -3.3087e-03,  3.6380e-02,\n",
              "                        4.9409e-03, -3.1245e-02,  2.5098e-02, -6.6251e-03, -3.8048e-02,\n",
              "                        9.0577e-03,  3.7961e-02, -9.0779e-04,  1.9775e-02,  4.5116e-02,\n",
              "                       -7.6870e-03, -3.1138e-03,  1.3645e-03, -1.6370e-02, -1.0451e-02,\n",
              "                        2.2689e-02, -1.1412e-02, -2.6955e-03,  7.7879e-03,  6.6994e-03,\n",
              "                        2.3677e-02,  1.0322e-02, -7.7839e-03,  1.4849e-02, -1.5029e-05,\n",
              "                       -2.0610e-05,  4.2975e-04,  7.6390e-05,  4.7187e-05, -1.8694e-05,\n",
              "                        3.1388e-04,  1.4448e-04, -1.1819e-04,  3.3111e-05, -2.0003e-04,\n",
              "                       -9.7072e-05, -4.6924e-04,  4.6538e-04,  2.4915e-04, -1.2781e-04,\n",
              "                       -1.0153e-04,  7.8802e-05, -9.3797e-05, -1.7188e-04,  2.1682e-04,\n",
              "                        1.5272e-04,  1.6351e-04, -1.1537e-04,  3.3188e-04, -1.1253e-04,\n",
              "                        3.2543e-04, -5.4918e-04, -5.4124e-04, -2.5914e-04,  3.4633e-04,\n",
              "                       -1.0237e-03, -7.9459e-04,  4.1485e-06, -2.8825e-04, -2.1537e-04,\n",
              "                        3.6454e-05, -3.7664e-04,  5.1432e-06,  2.2038e-04, -3.9192e-05,\n",
              "                        1.3144e-04,  3.8918e-04, -1.7941e-04, -3.5871e-04,  4.3256e-05,\n",
              "                        1.3197e-04, -7.3534e-05, -4.2017e-05,  5.5069e-05, -4.0026e-07,\n",
              "                        7.7297e-06, -6.6745e-05, -7.5361e-06, -4.0647e-05,  1.8440e-05,\n",
              "                       -2.3136e-04, -5.4366e-04,  1.3329e-04, -1.2048e-04,  7.1483e-04,\n",
              "                        2.0293e-04,  1.0221e-04,  2.1867e-04,  3.2606e-03, -8.4490e-03,\n",
              "                       -2.6632e-03, -5.2557e-03,  1.7405e-03, -1.4204e-03, -2.2608e-03,\n",
              "                       -4.3473e-04,  5.6619e-03, -1.2982e-02, -1.8091e-03, -1.3154e-02,\n",
              "                        1.1638e-02,  4.8387e-03, -2.7694e-03, -6.5569e-03,  5.9630e-03,\n",
              "                       -7.1718e-03,  4.0410e-03,  1.0455e-03, -3.9742e-04,  2.5473e-03,\n",
              "                       -1.7010e-03,  5.1852e-03, -2.2718e-03,  1.6363e-03,  9.8726e-04,\n",
              "                        1.1650e-02, -4.6129e-03,  2.7629e-03,  6.6839e-03,  3.9886e-04,\n",
              "                        7.8385e-03, -1.3949e-02, -3.4277e-03,  6.5916e-03, -3.0005e-04,\n",
              "                       -1.1599e-03,  7.2254e-03,  2.1760e-03,  2.6346e-03,  1.8492e-03,\n",
              "                        6.5714e-03,  3.6265e-03, -4.3886e-05,  2.7729e-03, -1.8684e-03,\n",
              "                        1.6846e-02,  3.8172e-03, -4.9571e-04,  7.3538e-03, -1.3795e-03,\n",
              "                        2.5761e-03, -1.6170e-03,  2.6855e-03,  9.6155e-04,  3.6992e-04,\n",
              "                       -4.8167e-03, -1.9315e-03,  1.1947e-02, -8.4392e-03,  3.5800e-03,\n",
              "                        4.2052e-03, -5.1417e-03], device='cuda:0')),\n",
              "              ('transformer.resblocks.5.attn.out_proj.weight',\n",
              "               tensor([[-0.0772, -0.0289, -0.0872,  ..., -0.0289, -0.0597, -0.0091],\n",
              "                       [-0.0569, -0.1161,  0.0103,  ..., -0.0096,  0.0940, -0.0126],\n",
              "                       [ 0.1299, -0.0246,  0.1162,  ..., -0.0203, -0.0357, -0.0947],\n",
              "                       ...,\n",
              "                       [ 0.1120, -0.0217,  0.0383,  ...,  0.0035, -0.0708,  0.0188],\n",
              "                       [ 0.0103, -0.0943, -0.1219,  ..., -0.0024, -0.0872, -0.1291],\n",
              "                       [ 0.0411, -0.0116,  0.0349,  ...,  0.0016, -0.0857, -0.0519]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.attn.out_proj.bias',\n",
              "               tensor([-0.0196,  0.0019,  0.0057, -0.0024,  0.0014, -0.0090, -0.0045,  0.0041,\n",
              "                       -0.0012, -0.0025, -0.0095,  0.0147,  0.0011,  0.0041,  0.0081,  0.0016,\n",
              "                       -0.0004, -0.0031,  0.0044, -0.0002,  0.0045, -0.0016, -0.0066,  0.0043,\n",
              "                        0.0059,  0.0204,  0.0154, -0.0046, -0.0070, -0.0068, -0.0162,  0.0024,\n",
              "                       -0.0008,  0.0030, -0.0108, -0.0013, -0.0044, -0.0023, -0.0055, -0.0139,\n",
              "                       -0.0002,  0.0033, -0.0012,  0.0103,  0.0089,  0.0070,  0.0042,  0.0091,\n",
              "                       -0.0011,  0.0004, -0.0015,  0.0040,  0.0086, -0.0078,  0.0016,  0.0070,\n",
              "                        0.0107, -0.0077, -0.0013, -0.0043,  0.0048, -0.0016, -0.0064,  0.0125],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.ln_1.weight',\n",
              "               tensor([0.9857, 0.9869, 1.0043, 1.0432, 1.0139, 1.0238, 1.0039, 0.9988, 1.0290,\n",
              "                       1.0437, 1.0330, 1.0192, 0.9923, 1.0181, 1.0143, 1.0226, 1.0220, 1.0212,\n",
              "                       1.0615, 1.0226, 0.9727, 1.0105, 1.0387, 1.0403, 1.0251, 1.0269, 1.0448,\n",
              "                       1.0402, 1.0230, 1.0370, 1.0195, 1.0325, 1.0250, 1.0080, 1.0398, 1.0197,\n",
              "                       1.0263, 0.9992, 1.0009, 1.0124, 1.0325, 1.0244, 1.0263, 1.0398, 1.0180,\n",
              "                       1.0379, 1.0099, 1.0084, 1.0392, 1.0379, 1.0280, 0.9960, 1.0131, 1.0131,\n",
              "                       0.9970, 1.0223, 1.0552, 1.0395, 1.0110, 1.0375, 1.0021, 0.9891, 1.0309,\n",
              "                       1.0080], device='cuda:0')),\n",
              "              ('transformer.resblocks.5.ln_1.bias',\n",
              "               tensor([ 0.0176, -0.0094,  0.0071, -0.0198,  0.0069, -0.0035, -0.0083,  0.0056,\n",
              "                        0.0327,  0.0373,  0.0366,  0.0217,  0.0107, -0.0093,  0.0259,  0.0225,\n",
              "                        0.0302, -0.0096, -0.0520,  0.0455,  0.0212, -0.0311,  0.0144, -0.0043,\n",
              "                       -0.0091,  0.0112,  0.0170, -0.0190,  0.0127,  0.0198,  0.0179, -0.0024,\n",
              "                       -0.0218,  0.0050, -0.0151, -0.0138, -0.0213,  0.0154, -0.0067,  0.0051,\n",
              "                        0.0351, -0.0249, -0.0111, -0.0332, -0.0202, -0.0270, -0.0118, -0.0105,\n",
              "                       -0.0268,  0.0016, -0.0095,  0.0002, -0.0091,  0.0222, -0.0012, -0.0070,\n",
              "                       -0.0429, -0.0363, -0.0082,  0.0239, -0.0024, -0.0177,  0.0235,  0.0061],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.mlp.0.weight',\n",
              "               tensor([[-0.0838, -0.0864, -0.0106,  ..., -0.0192,  0.1062, -0.1030],\n",
              "                       [ 0.0299, -0.0030, -0.0976,  ...,  0.0845, -0.0431,  0.0358],\n",
              "                       [ 0.0116,  0.0697, -0.1303,  ...,  0.0362, -0.0610,  0.0819],\n",
              "                       ...,\n",
              "                       [ 0.0166,  0.0577,  0.0401,  ..., -0.0509, -0.0776,  0.0852],\n",
              "                       [ 0.0977, -0.0178,  0.0688,  ..., -0.0788, -0.0552, -0.1083],\n",
              "                       [-0.0769,  0.1262,  0.0741,  ...,  0.0707, -0.0141,  0.0356]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.mlp.0.bias',\n",
              "               tensor([ 0.0236, -0.0746, -0.0092,  0.0873,  0.0212,  0.0173, -0.0026, -0.0815,\n",
              "                       -0.0206, -0.0787, -0.0095,  0.0658,  0.0307, -0.0633,  0.0773,  0.0736,\n",
              "                        0.0406, -0.0987, -0.0498, -0.1274, -0.0947,  0.0739,  0.0650,  0.0560,\n",
              "                        0.0520, -0.0474,  0.0142, -0.1165, -0.0665, -0.0878, -0.0018, -0.1045,\n",
              "                        0.0054,  0.0316,  0.0929, -0.0285,  0.0462, -0.0632, -0.0385,  0.0266,\n",
              "                       -0.0429,  0.1261,  0.0705,  0.0906,  0.0789, -0.0145,  0.0773,  0.1097,\n",
              "                        0.0406, -0.1189,  0.1022,  0.0823, -0.0768,  0.0664, -0.0829, -0.1121,\n",
              "                       -0.0891, -0.1382, -0.1166, -0.0303, -0.0590, -0.0477, -0.0915, -0.0604,\n",
              "                        0.0398, -0.0166, -0.1329, -0.1059,  0.0045,  0.0120, -0.0865,  0.0969,\n",
              "                        0.0052, -0.0141,  0.0277, -0.0133,  0.0682, -0.1087,  0.0229,  0.0473,\n",
              "                        0.0895, -0.0941,  0.0259,  0.0986,  0.0537,  0.1082, -0.1454, -0.0569,\n",
              "                        0.0158, -0.0889, -0.0223, -0.0413, -0.0047, -0.0044, -0.0432,  0.0050,\n",
              "                        0.1195, -0.1170, -0.0355,  0.0282, -0.1207,  0.1319,  0.0143,  0.0207,\n",
              "                       -0.0643, -0.0019, -0.0858,  0.0253,  0.0558,  0.0333, -0.1115, -0.1194,\n",
              "                        0.1099, -0.0182,  0.0370,  0.0135, -0.1175, -0.0112, -0.0340, -0.0533,\n",
              "                       -0.0754,  0.0087, -0.0132, -0.0996, -0.0809, -0.0284,  0.1162, -0.0550,\n",
              "                       -0.0030,  0.0245, -0.0947,  0.0400, -0.0809, -0.0924, -0.0010,  0.0699,\n",
              "                       -0.0087, -0.0773,  0.1146, -0.0568,  0.0404, -0.0553,  0.0366,  0.0562,\n",
              "                       -0.0835,  0.0902, -0.0083, -0.0500, -0.0378, -0.0128, -0.1103, -0.0282,\n",
              "                        0.0986, -0.1021,  0.0614, -0.0831, -0.1140,  0.1142,  0.0689, -0.0989,\n",
              "                        0.0504,  0.0646, -0.0264, -0.1061, -0.0616, -0.0488,  0.0862, -0.0745,\n",
              "                        0.0157,  0.0032, -0.0798, -0.1226,  0.0405,  0.0802,  0.0174, -0.0944,\n",
              "                        0.0547,  0.0139, -0.0277, -0.0144, -0.0710,  0.0851, -0.0186, -0.0926,\n",
              "                        0.0837, -0.0115,  0.0965, -0.0234, -0.0823,  0.0094,  0.0598,  0.0163,\n",
              "                        0.0963,  0.0655,  0.0383,  0.0883,  0.1325,  0.0388, -0.0291, -0.1188,\n",
              "                       -0.1441,  0.1001,  0.0060,  0.0313,  0.1010, -0.1074,  0.1318,  0.0695,\n",
              "                       -0.0503,  0.0140,  0.0559,  0.0286, -0.0399,  0.0848, -0.0175,  0.1061,\n",
              "                        0.1165,  0.0753,  0.0281,  0.0363, -0.0950, -0.0342, -0.0594,  0.0431,\n",
              "                       -0.0944,  0.1194,  0.0806, -0.1078,  0.1291, -0.1326,  0.1045,  0.0599,\n",
              "                       -0.0252, -0.0384, -0.0317, -0.0897,  0.1021,  0.0391,  0.1086,  0.0636,\n",
              "                        0.1062,  0.0402, -0.0083,  0.0159,  0.0313, -0.0947, -0.0926, -0.0988,\n",
              "                        0.0378,  0.0851, -0.0135, -0.0522, -0.0638, -0.0217,  0.1249, -0.0794],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.mlp.2.weight',\n",
              "               tensor([[-0.0084, -0.0049, -0.0861,  ...,  0.0285, -0.0709, -0.0124],\n",
              "                       [-0.0194,  0.0058,  0.0133,  ..., -0.0549,  0.0539,  0.0324],\n",
              "                       [ 0.0443, -0.0306,  0.0551,  ..., -0.0200, -0.0670, -0.0610],\n",
              "                       ...,\n",
              "                       [ 0.0485, -0.0485,  0.0335,  ...,  0.0289,  0.0327,  0.0237],\n",
              "                       [ 0.0337,  0.0130, -0.0031,  ..., -0.0529, -0.0281,  0.0706],\n",
              "                       [-0.0538,  0.0478,  0.0492,  ..., -0.0207, -0.0362, -0.0151]],\n",
              "                      device='cuda:0')),\n",
              "              ('transformer.resblocks.5.mlp.2.bias',\n",
              "               tensor([-3.3898e-02,  6.8354e-03,  3.8846e-02, -4.8204e-02, -1.9411e-02,\n",
              "                       -1.4236e-02, -3.4838e-02, -2.5705e-02,  5.8420e-02,  2.3118e-02,\n",
              "                       -7.9556e-03,  5.1986e-05,  6.5592e-02, -3.3290e-02,  1.3484e-03,\n",
              "                       -1.2467e-02, -1.1120e-02, -1.5360e-02, -4.1502e-02, -5.0472e-02,\n",
              "                        4.5598e-02, -5.6699e-02,  3.6436e-02,  7.1502e-02, -3.4889e-02,\n",
              "                        5.5473e-02, -1.0470e-02, -3.6505e-02,  2.8352e-02, -4.7690e-02,\n",
              "                       -9.9074e-03,  2.7439e-02, -3.9072e-02,  6.7644e-02, -6.8872e-02,\n",
              "                       -6.3168e-02,  1.3945e-02,  5.6817e-02,  7.7797e-03, -2.1055e-02,\n",
              "                        2.9876e-02, -1.0131e-02, -5.8399e-02,  9.4840e-03, -4.8181e-02,\n",
              "                       -2.7588e-03,  9.7309e-03,  6.0847e-02, -2.7108e-02, -3.8170e-02,\n",
              "                        2.2826e-02, -2.5298e-02,  9.8534e-03, -6.3875e-02,  3.1116e-02,\n",
              "                       -4.6591e-03, -5.3978e-02, -3.7435e-02, -2.0526e-02,  4.6383e-02,\n",
              "                       -6.0350e-02,  2.4842e-02, -1.5896e-03,  3.1855e-02], device='cuda:0')),\n",
              "              ('transformer.resblocks.5.ln_2.weight',\n",
              "               tensor([1.0403, 1.0069, 1.0188, 1.0464, 0.9961, 1.0314, 1.0094, 1.0346, 1.0240,\n",
              "                       1.0080, 1.0137, 0.9990, 1.0350, 1.0169, 1.0216, 1.0294, 1.0531, 1.0159,\n",
              "                       1.0091, 1.0332, 1.0149, 1.0389, 1.0120, 1.0031, 1.0242, 1.0377, 1.0071,\n",
              "                       1.0204, 1.0159, 1.0147, 1.0403, 1.0426, 1.0139, 1.0212, 1.0218, 1.0209,\n",
              "                       1.0033, 1.0178, 1.0245, 1.0143, 1.0114, 1.0376, 1.0205, 1.0425, 1.0256,\n",
              "                       1.0240, 1.0206, 1.0390, 1.0301, 1.0245, 1.0160, 1.0057, 1.0264, 1.0315,\n",
              "                       1.0116, 1.0269, 1.0062, 1.0287, 0.9972, 1.0131, 1.0358, 0.9898, 0.9999,\n",
              "                       1.0150], device='cuda:0')),\n",
              "              ('transformer.resblocks.5.ln_2.bias',\n",
              "               tensor([-0.0071,  0.0034,  0.0167, -0.0092,  0.0061,  0.0102, -0.0024, -0.0002,\n",
              "                       -0.0039,  0.0058,  0.0121,  0.0005,  0.0035,  0.0157,  0.0065,  0.0029,\n",
              "                       -0.0108, -0.0019,  0.0036, -0.0023,  0.0014,  0.0070,  0.0049, -0.0161,\n",
              "                       -0.0039, -0.0057, -0.0082,  0.0020,  0.0032, -0.0182, -0.0138,  0.0167,\n",
              "                       -0.0081,  0.0061, -0.0118,  0.0081, -0.0183, -0.0144,  0.0058, -0.0026,\n",
              "                       -0.0109,  0.0044,  0.0177,  0.0044,  0.0059,  0.0035,  0.0018, -0.0072,\n",
              "                       -0.0014,  0.0110, -0.0038, -0.0021,  0.0023, -0.0047,  0.0070, -0.0046,\n",
              "                       -0.0086, -0.0003,  0.0044, -0.0099,  0.0073,  0.0100, -0.0052,  0.0110],\n",
              "                      device='cuda:0')),\n",
              "              ('ln_post.weight',\n",
              "               tensor([1.0195, 1.0102, 0.9925, 1.0063, 1.0038, 1.0063, 1.0085, 0.9851, 1.0030,\n",
              "                       1.0096, 0.9896, 0.9942, 0.9867, 1.0081, 1.0110, 1.0082, 1.0054, 1.0183,\n",
              "                       1.0041, 1.0016, 1.0011, 0.9956, 0.9916, 1.0041, 1.0099, 0.9990, 0.9950,\n",
              "                       0.9935, 1.0067, 0.9854, 1.0035, 0.9952, 1.0104, 0.9888, 1.0042, 1.0024,\n",
              "                       0.9997, 0.9831, 1.0020, 0.9998, 1.0010, 1.0047, 1.0068, 1.0130, 0.9939,\n",
              "                       0.9916, 0.9627, 1.0096, 1.0215, 0.9991, 0.9892, 1.0015, 0.9943, 1.0150,\n",
              "                       1.0025, 0.9936, 0.9829, 1.0064, 1.0062, 0.9902, 1.0030, 0.9938, 1.0000,\n",
              "                       1.0138], device='cuda:0')),\n",
              "              ('ln_post.bias',\n",
              "               tensor([-3.2994e-02,  9.5290e-04,  1.6774e-02, -1.3842e-02,  1.1475e-02,\n",
              "                       -1.6483e-02, -2.6502e-02,  7.1265e-03,  1.4912e-02,  2.2415e-02,\n",
              "                       -1.3777e-02,  3.6011e-02,  1.5583e-02, -1.5906e-03,  2.4420e-02,\n",
              "                        1.8280e-02,  8.8973e-03, -1.1213e-02, -1.3437e-02,  6.6424e-05,\n",
              "                        2.4129e-02, -1.5917e-02, -2.3821e-02,  2.7506e-02,  1.2565e-02,\n",
              "                        3.3091e-02,  2.3574e-02, -1.2448e-02, -7.1997e-03,  4.9207e-03,\n",
              "                       -2.6305e-02,  5.0844e-03, -9.4594e-03,  8.1958e-03, -2.0255e-02,\n",
              "                       -1.6885e-02, -2.6509e-03,  1.1834e-02, -1.2584e-03, -2.4728e-02,\n",
              "                        1.7725e-02, -1.5324e-02, -1.7273e-02,  3.0583e-03,  1.3969e-02,\n",
              "                       -4.6816e-03, -7.1252e-03,  2.3069e-02, -1.6114e-02, -1.4061e-02,\n",
              "                       -1.3402e-02,  1.7944e-02,  1.9662e-02, -6.5487e-04,  1.4085e-02,\n",
              "                        8.5239e-03, -1.3073e-04, -2.8047e-02, -2.1798e-02,  7.9730e-04,\n",
              "                       -1.5586e-03, -2.2002e-02,  6.7803e-03,  3.1772e-02], device='cuda:0'))]),\n",
              " 'classifier': OrderedDict([('classifier.weight',\n",
              "               tensor([[-2.1748e-01, -5.2604e-02, -1.5807e-01,  9.0247e-02, -1.9094e-01,\n",
              "                        -1.0814e-01,  2.0377e-01,  6.4617e-02, -3.0165e-02,  1.5318e-01,\n",
              "                         1.3733e-01, -7.3904e-02, -1.2456e-01,  1.0862e-01, -1.3583e-01,\n",
              "                        -1.2651e-01,  8.3591e-03,  9.8275e-02,  1.4506e-01, -1.2060e-01,\n",
              "                        -2.8742e-03, -1.4670e-01,  3.3839e-02,  2.3902e-01, -2.5254e-01,\n",
              "                         2.3780e-01,  1.3418e-01,  2.3425e-01, -4.8629e-02, -1.1469e-01,\n",
              "                        -2.5478e-01,  8.0027e-02, -4.8531e-02, -1.4172e-01,  1.5894e-01,\n",
              "                         1.2013e-01, -2.8497e-01,  1.4631e-01, -1.7116e-01, -2.1889e-01,\n",
              "                         7.1881e-02,  1.9924e-01,  1.9279e-01, -6.4954e-02,  1.8988e-01,\n",
              "                         1.4386e-01,  1.8099e-01,  1.2795e-01, -2.1388e-01,  2.0499e-01,\n",
              "                        -1.1686e-01, -1.1670e-02,  1.2713e-01,  1.1752e-01,  3.0519e-01,\n",
              "                        -9.2464e-02, -6.4879e-02, -1.4738e-01, -9.2793e-02, -1.1676e-01,\n",
              "                         6.1184e-02,  1.6867e-01,  1.3570e-01, -1.9817e-01],\n",
              "                       [-2.0459e-01,  1.0011e-01, -1.5961e-01,  2.7372e-01, -1.8496e-01,\n",
              "                        -8.4151e-02,  1.1892e-01, -2.8093e-01, -1.1107e-01,  1.7249e-02,\n",
              "                         2.4334e-01,  2.5385e-01, -1.5755e-01, -6.0939e-02, -1.8219e-01,\n",
              "                         1.1976e-02,  1.0517e-01,  1.2613e-01, -9.6113e-02,  3.1645e-01,\n",
              "                         1.5717e-01,  1.5726e-01, -2.9806e-01,  2.2327e-01,  9.8537e-02,\n",
              "                         9.3459e-02,  7.6718e-02, -2.7234e-01,  4.8698e-02, -1.9119e-01,\n",
              "                         1.1320e-01,  1.4810e-01, -2.9316e-01, -5.3014e-03, -3.0819e-01,\n",
              "                        -1.1342e-01,  1.0282e-01, -1.4474e-01,  1.6026e-01,  2.2823e-01,\n",
              "                        -5.4506e-02, -9.9117e-02,  1.8088e-01,  9.5191e-02, -1.2530e-01,\n",
              "                         1.4854e-01,  2.2126e-01,  2.1417e-01,  2.0923e-01, -9.4768e-02,\n",
              "                        -2.9701e-01,  2.8312e-03, -1.9419e-01,  2.5422e-01, -1.7665e-01,\n",
              "                        -3.1544e-01,  2.0537e-01, -9.5909e-02,  7.5696e-02, -1.0076e-01,\n",
              "                         2.6300e-01, -1.6267e-01, -1.8110e-01,  1.3562e-01],\n",
              "                       [-1.6688e-01,  7.5834e-02, -8.5915e-02, -1.3284e-01,  1.5875e-01,\n",
              "                        -2.4309e-01,  4.5689e-02, -3.5698e-01,  1.4990e-01,  3.1439e-02,\n",
              "                        -1.4729e-01,  1.4372e-01, -2.0404e-01, -4.5410e-02, -1.3712e-01,\n",
              "                         1.5876e-01, -2.0508e-01, -2.3503e-01,  3.7751e-01, -3.8697e-02,\n",
              "                        -1.8788e-01,  2.7197e-01, -6.0945e-03, -1.5005e-01,  1.8032e-01,\n",
              "                        -6.2890e-02,  2.5428e-01, -1.8152e-01, -2.2451e-01, -2.2901e-01,\n",
              "                        -3.0464e-01,  1.9255e-01, -5.6806e-02, -7.2843e-02, -9.6738e-02,\n",
              "                         6.3100e-02,  1.5426e-01,  8.8406e-02, -2.5097e-01,  8.5535e-02,\n",
              "                         3.2931e-01, -5.0356e-02,  3.5343e-02,  1.3257e-01,  1.4251e-01,\n",
              "                         2.4536e-01,  1.2333e-01, -1.7913e-01,  1.4667e-01,  1.3412e-01,\n",
              "                        -1.6274e-01, -1.4422e-01, -1.6729e-01,  1.1058e-01,  2.6915e-02,\n",
              "                        -6.6835e-02, -1.5974e-01,  9.2572e-02,  1.4864e-01,  3.9216e-02,\n",
              "                        -9.5946e-02, -5.3833e-03,  1.4702e-01,  2.1708e-01],\n",
              "                       [-1.9202e-01, -1.3186e-02, -9.7368e-02,  1.7081e-01,  2.7543e-01,\n",
              "                        -1.5196e-01, -1.1184e-01, -6.0007e-02, -2.0258e-01, -1.4394e-01,\n",
              "                         1.3937e-01,  1.3844e-01, -1.3719e-01,  1.8251e-01,  1.7194e-01,\n",
              "                         1.3367e-01,  1.8068e-01, -1.2835e-01,  3.3281e-01, -2.4988e-01,\n",
              "                        -1.3976e-01,  1.5937e-02, -2.1580e-01,  1.3300e-01, -1.6070e-01,\n",
              "                         2.4652e-01, -3.2734e-02, -1.3192e-01,  8.5792e-02, -1.0366e-01,\n",
              "                         2.7752e-01,  2.9186e-01,  1.1929e-01,  1.0217e-02,  1.9291e-01,\n",
              "                        -1.5000e-01, -1.7472e-02,  5.2898e-02,  1.7264e-01, -2.7103e-01,\n",
              "                        -6.0791e-02, -2.2393e-01,  5.7253e-02, -2.2970e-01,  1.5047e-01,\n",
              "                        -1.2968e-01, -1.4561e-02, -1.4147e-01, -6.8063e-02, -6.8793e-02,\n",
              "                         7.6035e-02,  6.4608e-02, -2.3905e-01, -9.3028e-02,  2.3277e-01,\n",
              "                        -1.5267e-01, -1.1147e-01, -1.9336e-01, -1.7840e-01, -1.5919e-01,\n",
              "                        -1.3551e-01, -6.8587e-02, -1.1928e-01,  2.4125e-01],\n",
              "                       [ 3.0188e-02, -1.3561e-01, -1.9199e-01, -7.7815e-02,  1.4666e-01,\n",
              "                        -3.1368e-01, -1.5317e-01,  1.1299e-01,  2.0282e-01, -1.7392e-01,\n",
              "                        -1.8468e-01,  2.5003e-01,  6.1904e-02,  2.8265e-02,  1.1446e-01,\n",
              "                         2.5409e-01,  9.9996e-02, -2.3872e-01,  6.5735e-02, -6.3978e-02,\n",
              "                        -2.9635e-01,  1.5261e-01,  1.9398e-01, -2.9347e-01,  1.0464e-01,\n",
              "                        -9.8923e-03,  1.1764e-01, -2.7070e-01,  1.9342e-01, -5.2549e-02,\n",
              "                        -1.1912e-01, -1.9984e-01,  1.8118e-01, -2.0866e-01, -6.6461e-02,\n",
              "                        -2.1885e-01,  1.3478e-01,  2.2335e-01, -1.4163e-01,  1.4628e-01,\n",
              "                         3.1256e-02, -1.1832e-01, -6.6900e-02,  2.9292e-01, -2.4649e-01,\n",
              "                         3.7419e-01, -3.1923e-01, -1.8713e-01,  1.8860e-01, -2.0438e-01,\n",
              "                        -1.4953e-01, -2.2998e-01,  2.7666e-01, -3.8217e-01,  2.2552e-01,\n",
              "                        -2.5127e-01,  1.5433e-01,  4.6919e-02,  9.2153e-02,  6.3954e-02,\n",
              "                        -1.5788e-01,  8.1226e-02, -1.6635e-01,  2.9251e-01],\n",
              "                       [-1.1639e-01,  2.0942e-01,  1.5334e-01, -6.3824e-02, -1.2897e-01,\n",
              "                         1.5711e-01,  8.9719e-02, -2.3873e-01, -1.9599e-01, -4.7038e-02,\n",
              "                        -1.5124e-01, -1.0905e-01,  4.9607e-02,  1.9189e-01,  1.0932e-01,\n",
              "                        -1.4928e-01, -2.3662e-01, -3.1504e-01, -2.3710e-01,  2.7185e-01,\n",
              "                         2.3631e-01,  7.6808e-02,  1.9882e-01,  1.2456e-01,  1.4100e-01,\n",
              "                        -3.2750e-01, -2.4839e-01,  2.2886e-02, -3.4906e-01, -6.4019e-02,\n",
              "                        -1.3333e-02,  7.0718e-02,  2.2829e-01, -1.3922e-01, -2.7722e-02,\n",
              "                         2.6989e-01, -2.1844e-01, -2.0146e-01, -1.7167e-01,  1.1472e-01,\n",
              "                        -1.9933e-01, -2.1067e-01,  2.6338e-01, -1.3595e-01,  1.0937e-01,\n",
              "                        -9.8915e-02, -1.4872e-01,  1.3921e-01,  2.2006e-01,  1.7248e-01,\n",
              "                        -5.1456e-02,  1.3512e-01, -1.4648e-01,  2.5568e-01, -2.3426e-01,\n",
              "                         2.9898e-01, -3.3469e-02, -3.8311e-02,  1.9937e-01, -2.1377e-01,\n",
              "                         2.5669e-01,  1.1840e-01, -2.7393e-01,  1.5101e-01],\n",
              "                       [-1.4589e-01, -1.4466e-01,  5.4796e-02,  1.1286e-01,  9.3411e-02,\n",
              "                        -2.6554e-01,  2.9269e-01,  1.6031e-01,  1.3838e-01,  7.0659e-02,\n",
              "                        -9.1934e-02, -9.4111e-02, -1.3605e-02, -7.1489e-02, -3.5416e-02,\n",
              "                        -1.8292e-02, -6.6102e-02, -2.9100e-01,  1.5847e-01, -1.5794e-01,\n",
              "                        -1.4418e-01, -2.6116e-01,  7.2349e-02, -1.8257e-01,  2.8286e-02,\n",
              "                         1.3019e-01,  1.5457e-01, -5.2717e-02,  1.0112e-01, -1.6652e-01,\n",
              "                        -2.4706e-02,  7.8635e-03, -1.4543e-01, -3.2897e-01,  9.4100e-02,\n",
              "                         2.0144e-01,  2.1290e-01,  2.1153e-01, -7.9243e-02, -6.1535e-02,\n",
              "                        -8.0970e-02,  1.8405e-01, -2.4077e-01,  1.7287e-01,  1.6313e-01,\n",
              "                         1.5632e-01,  8.8615e-02, -4.7836e-02, -1.3202e-01,  1.4834e-01,\n",
              "                        -8.6025e-03, -3.9657e-02,  1.2611e-01, -4.1503e-01,  1.2101e-01,\n",
              "                        -3.4778e-02,  2.9788e-02, -1.5829e-01, -1.1553e-01,  3.9999e-02,\n",
              "                        -5.4848e-02, -1.9831e-02,  1.6807e-01, -1.3127e-01],\n",
              "                       [ 3.2679e-01, -1.4886e-02,  2.4682e-01,  1.6633e-01, -3.5314e-01,\n",
              "                        -8.2761e-02, -1.7204e-01, -3.3464e-01,  1.0940e-02,  7.7792e-02,\n",
              "                        -1.8296e-01, -1.0184e-01,  8.8322e-02,  9.9155e-02, -3.2636e-01,\n",
              "                        -2.0326e-01, -1.3717e-01,  3.2527e-01, -1.5297e-01, -7.3356e-04,\n",
              "                         1.1901e-01,  3.4093e-01,  2.9201e-01,  1.9196e-01, -1.8505e-01,\n",
              "                        -7.9677e-02, -1.9017e-01,  1.9609e-01,  1.3703e-01,  2.2873e-01,\n",
              "                         1.6290e-01, -9.9668e-02,  2.4359e-01,  6.1884e-02,  8.1554e-02,\n",
              "                        -9.9648e-02, -1.1603e-01, -1.9663e-01,  3.5650e-01, -2.8081e-01,\n",
              "                        -3.0402e-01,  2.3382e-01, -8.0591e-02, -8.7828e-02, -7.7086e-02,\n",
              "                        -1.0232e-01, -5.9894e-02,  1.0358e-03,  3.6620e-01,  5.0633e-02,\n",
              "                        -1.5920e-01, -5.6085e-02,  1.1865e-01, -1.6281e-01,  6.5203e-03,\n",
              "                         1.5791e-01,  9.8029e-02,  2.1933e-01,  2.6392e-02,  8.4351e-02,\n",
              "                        -2.2545e-01, -2.9742e-01, -1.9029e-01, -2.5378e-01],\n",
              "                       [ 1.2184e-01,  1.0188e-01,  4.5156e-02, -1.8365e-01,  1.2106e-01,\n",
              "                         8.9316e-02, -1.1939e-01,  2.6821e-01,  8.3327e-02, -2.1049e-01,\n",
              "                        -5.0524e-02, -6.6606e-02, -4.3547e-02, -1.5858e-01, -1.2292e-01,\n",
              "                        -1.0708e-01,  1.1152e-01,  1.2629e-01, -1.9411e-01, -1.7143e-01,\n",
              "                         2.2762e-01, -1.6083e-01, -3.6027e-01, -3.0817e-01, -7.0244e-02,\n",
              "                        -2.2492e-01,  1.5342e-01,  1.2394e-03, -4.5229e-02,  1.4446e-02,\n",
              "                         6.3653e-02, -2.6514e-01,  4.3551e-02,  1.0031e-01,  1.0361e-01,\n",
              "                        -2.2011e-01,  3.0572e-01, -1.8849e-01, -3.6167e-01, -1.7126e-01,\n",
              "                         2.8674e-01, -1.6643e-02, -1.3704e-01,  6.8277e-02, -1.4562e-01,\n",
              "                        -1.7121e-01, -2.0575e-02,  1.6244e-01, -6.5242e-02,  1.1724e-01,\n",
              "                        -1.0165e-01, -1.2197e-01,  2.2985e-01,  2.5011e-01, -2.3186e-02,\n",
              "                         2.8284e-01, -9.4632e-02, -2.5710e-01,  1.4101e-01, -1.7974e-01,\n",
              "                         9.6819e-02, -1.2606e-01,  1.9199e-01, -2.0963e-01],\n",
              "                       [ 1.5320e-01,  1.6762e-01,  6.6349e-02, -1.5445e-01, -2.9874e-01,\n",
              "                        -8.3791e-02, -1.9101e-01, -3.6923e-02, -1.1088e-01, -2.1197e-03,\n",
              "                         2.0454e-01, -1.5354e-01,  1.4797e-01,  3.0150e-01,  1.1406e-01,\n",
              "                        -1.0137e-01, -1.1206e-01,  1.9965e-01, -7.0346e-02,  2.2605e-01,\n",
              "                        -2.3113e-01,  2.7081e-01, -2.2103e-01, -3.3292e-01, -1.9063e-01,\n",
              "                        -1.8368e-01, -1.8966e-01,  2.9279e-01,  2.9432e-01, -8.8632e-02,\n",
              "                         2.8724e-02,  2.3816e-01,  2.4060e-01,  1.3276e-01,  2.2765e-01,\n",
              "                         2.4709e-01, -5.4874e-02, -1.7244e-01,  4.6341e-02,  3.0350e-01,\n",
              "                        -7.6367e-02, -3.2082e-01,  2.8093e-01, -2.8998e-01,  3.1181e-01,\n",
              "                        -1.9484e-01,  1.9088e-01, -2.8678e-04, -1.2912e-01, -8.7082e-02,\n",
              "                         3.6697e-01,  2.3242e-01, -1.8761e-01, -2.1774e-01,  1.7829e-01,\n",
              "                         2.5998e-01,  9.2232e-02,  3.4589e-01, -1.8335e-01,  2.4437e-01,\n",
              "                        -8.6252e-02,  1.7978e-01, -3.1911e-01,  3.7849e-03]], device='cuda:0')),\n",
              "              ('classifier.bias',\n",
              "               tensor([-0.0839,  0.0086,  0.1690, -0.0569, -0.0133,  0.0413,  0.0270,  0.0232,\n",
              "                       -0.0118, -0.0029], device='cuda:0'))])}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train a deep classifier in 5 epochs\n",
        "train_classification_model_head_only(vit_model, train_dataset, test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
